{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4.mnist_cnn_class.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzKe_plWr-CU","executionInfo":{"status":"ok","timestamp":1660805023398,"user_tz":-540,"elapsed":64860,"user":{"displayName":"­이지섭 / 학생 / 컴퓨터공학부","userId":"00338471247721163680"}},"outputId":"0afb1a18-3c70-4518-8626-025b35fe7e64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","The following packages will be REMOVED:\n","  libcudnn8-dev\n","The following held packages will be changed:\n","  libcudnn8\n","The following packages will be upgraded:\n","  libcudnn8\n","1 upgraded, 0 newly installed, 1 to remove and 18 not upgraded.\n","Need to get 430 MB of archives.\n","After this operation, 3,139 MB disk space will be freed.\n","Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n","Fetched 430 MB in 14s (30.0 MB/s)\n","(Reading database ... 155676 files and directories currently installed.)\n","Removing libcudnn8-dev (8.0.5.39-1+cuda11.1) ...\n","(Reading database ... 155654 files and directories currently installed.)\n","Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n","Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.0.5.39-1+cuda11.1) ...\n","Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P2Ogm8nB863D"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","tf.random.set_seed(777)\n","\n","learning_rate = 0.001\n","training_epochs = 15\n","batch_size = 100"]},{"cell_type":"code","source":["mnist = keras.datasets.mnist\n","class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()    \n","    \n","train_images = x_train.astype(np.float32) / 255.\n","test_images = x_test.astype(np.float32) / 255.\n","train_images = np.expand_dims(train_images, axis=-1)\n","test_images = np.expand_dims(test_images, axis=-1)\n","\n","#One hot Encoding  \n","train_labels = to_categorical(y_train, 10)\n","test_labels = to_categorical(y_test, 10)\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(buffer_size=100000).batch(batch_size)\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)"],"metadata":{"id":"YZ3MFqtq9DJg","executionInfo":{"status":"ok","timestamp":1660834099270,"user_tz":-540,"elapsed":7544,"user":{"displayName":"Soonhoi Ha","userId":"02814229244148959220"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"eb5c5004-db80-4331-e44c-e452263da318"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["class MNISTModel(tf.keras.Model):\n","    def __init__(self):\n","        super(MNISTModel, self).__init__() \n","        self.conv1 = keras.layers.Conv2D(filters=32, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n","        self.pool1 = keras.layers.MaxPool2D(padding='SAME')\n","        self.conv2 = keras.layers.Conv2D(filters=64, kernel_size=[3, 3], padding='SAME', activation=tf.nn.relu)\n","        self.pool2 = keras.layers.MaxPool2D(padding='SAME')\n","        self.pool2_flat = keras.layers.Flatten()\n","        self.dense3 = keras.layers.Dense(units=10)\n","\n","    def call(self, inputs, training=False):\n","        net = self.conv1(inputs)\n","        net = self.pool1(net)\n","        net = self.conv2(net)\n","        net = self.pool2(net)\n","        net = self.pool2_flat(net)\n","        net = self.dense3(net)\n","        \n","        return net\n","\n","model = MNISTModel()\n","temp_inputs = keras.Input(shape=(28, 28, 1))\n","model(temp_inputs)\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EstzFTpL9D1X","executionInfo":{"status":"ok","timestamp":1660834553245,"user_tz":-540,"elapsed":721,"user":{"displayName":"Soonhoi Ha","userId":"02814229244148959220"}},"outputId":"a6d287fd-480d-4cab-aec9-69dd2087c9ad"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"mnist_model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_4 (Conv2D)           multiple                  320       \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           multiple                  18496     \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  multiple                 0         \n"," 2D)                                                             \n","                                                                 \n"," flatten_2 (Flatten)         multiple                  0         \n","                                                                 \n"," dense_2 (Dense)             multiple                  31370     \n","                                                                 \n","=================================================================\n","Total params: 50,186\n","Trainable params: 50,186\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["def loss_fn(model, images, labels): \n","    logits = model(images, training=True)\n","    loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n","        y_pred=logits, y_true=labels, from_logits=True))    \n","    return loss\n","\n","def grad(model, images, labels): \n","    with tf.GradientTape() as tape:\n","        loss = loss_fn(model, images, labels)\n","    return tape.gradient(loss, model.variables)  \n","\n","def evaluate(model, images, labels):\n","    logits = model(images, training=False)\n","    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n","    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n","    return accuracy\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"],"metadata":{"id":"alKCBlQ29Tlf","executionInfo":{"status":"ok","timestamp":1660834569294,"user_tz":-540,"elapsed":495,"user":{"displayName":"Soonhoi Ha","userId":"02814229244148959220"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def train(model, images, labels):\n","    grads = grad(model, images, labels)\n","    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","print('Learning started. It takes sometime.')\n","for epoch in range(training_epochs): \n","    avg_loss = 0.\n","    avg_train_acc = 0.\n","    avg_test_acc = 0.\n","    train_step = 0\n","    test_step = 0    \n","    \n","    for images, labels in train_dataset:\n","        train(model, images, labels)\n","        loss = loss_fn(model, images, labels)\n","        acc = evaluate(model, images, labels)\n","        avg_loss = avg_loss + loss\n","        avg_train_acc = avg_train_acc + acc\n","        train_step += 1\n","        \n","    avg_loss = avg_loss / train_step\n","    avg_train_acc = avg_train_acc / train_step\n","    \n","    for images, labels in test_dataset:        \n","        acc = evaluate(model, images, labels)        \n","        avg_test_acc = avg_test_acc + acc\n","        test_step += 1    \n","    avg_test_acc = avg_test_acc / test_step    \n","\n","    print('Epoch:', '{}'.format(epoch + 1), 'loss =', '{:.8f}'.format(avg_loss), \n","          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n","          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n","    \n","print('Learning Finished!')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":517},"id":"Gm_c0-3C9WpQ","outputId":"3ded7d76-d363-4734-96a6-746b6871b2ab","executionInfo":{"status":"error","timestamp":1660834575788,"user_tz":-540,"elapsed":533,"user":{"displayName":"Soonhoi Ha","userId":"02814229244148959220"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Learning started. It takes sometime.\n"]},{"output_type":"error","ename":"UnimplementedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-af0957cdd36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-af0957cdd36f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, images, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Learning started. It takes sometime.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-114728004946>\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(model, images, labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-114728004946>\u001b[0m in \u001b[0;36mloss_fn\u001b[0;34m(model, images, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(\n\u001b[1;32m      4\u001b[0m         y_pred=logits, y_true=labels, from_logits=True))    \n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-4a913a03e7f5>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnimplementedError\u001b[0m: Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nDNN library is not found. [Op:Conv2D]\n\nCall arguments received by layer \"conv2d_4\" (type Conv2D):\n  • inputs=tf.Tensor(shape=(100, 28, 28, 1), dtype=float32)"]}]}]}