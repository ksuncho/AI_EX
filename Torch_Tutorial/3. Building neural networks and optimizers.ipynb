{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3. Building neural networks and optimizers.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"j8GcSJyaNBo9"},"source":["Recommended materials\n","====\n","\n","1. Pytorch Official Tutorial \\[[Link](https://pytorch.org/tutorials/)\\]\n","2. DeepLearning Zero to All \\[[English](https://www.youtube.com/playlist?list=PLlMkM4tgfjnJ3I-dbhO9JTw7gNty6o_2m)\\] \\[[Korean](https://www.youtube.com/playlist?list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv)\\]\n","3. Neural Network Programming - Deep Learning with Pytorch \\[[English](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG)\\]"]},{"cell_type":"markdown","metadata":{"id":"W0JsEBb2t1Hd"},"source":["Building Neural Networks and Constructing Optimizers\n","=====\n","\n"]},{"cell_type":"markdown","metadata":{"id":"-arhhdSZ6Pk4"},"source":["## Key Modules & Functions for building neural networks\n","- `torch.nn`\n","- `torch.nn.functional`\n","- MLP : `torch.nn.Linear`\n","- Convolutional Layer : `torch.nn.Conv2d`, `torch.nn.ConvTranspose2d`\n","- Dropout : `torch.nn.Dropout1d`, `torch.nn.Dropout2d`\n","- Batch normalization : `torch.nn.BatchNorm1d`, `torch.nn.BatchNorm2d`\n","- Sigmoid : `torch.nn.Sigmoid`, `torch.nn.functional.sigmoid`\n","- Tanh : `torch.nn.Tanh`, `torch.nn.functional.tanh`\n","- Softmax : `torch.nn.Softmax`, `torch.nn.functional.softmax`\n","- ReLU : `torch.nn.ReLU`, `torch.nn.functional.relu`\n","- LeakyReLU : `torch.nn.LeakyReLU`, `torch.nn.functional.leaky_relu`"]},{"cell_type":"markdown","metadata":{"id":"HJkrRjPI6CqM"},"source":["## Example 1. A simple MLP  \n","![](https://drive.google.com/uc?export=view&id=1_CUhZor5dcxcL9K1g-vnExZ04vVt7SV5)"]},{"cell_type":"code","metadata":{"id":"veS0ZghE6wKT"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# set (hyper-)parameters\n","input_dim = 10\n","hidden1_dim = 20\n","hidden2_dim = 30\n","hidden3_dim = 40\n","hidden4_dim = 50\n","output_dim = 1\n","batch_size = 5\n","\n","# build a neural network\n","mlp1 = nn.Linear(input_dim, hidden1_dim)\n","mlp2 = nn.Linear(hidden1_dim, hidden2_dim)\n","mlp3 = nn.Linear(hidden2_dim, hidden3_dim)\n","mlp4 = nn.Linear(hidden3_dim, hidden4_dim)\n","mlp5 = nn.Linear(hidden4_dim, output_dim)\n","\n","# get an input data\n","inputs = torch.randn(batch_size, input_dim)\n","\n","# feed the data into the network layers\n","hidden1 = mlp1(inputs)\n","hidden2 = mlp2(hidden1)\n","hidden3 = mlp3(hidden2)\n","hidden4 = mlp4(hidden3)\n","outputs = mlp5(hidden4)\n","\n","# check output shapes\n","print(inputs.shape)\n","print(hidden1.shape)\n","print(hidden2.shape)\n","print(hidden3.shape)\n","print(hidden4.shape)\n","print(outputs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PAkypxEA9DIp"},"source":["## Example 2. A MLP with ReLU, DropOut(p), and Batch Normalization  \n","![](https://drive.google.com/uc?export=view&id=1UDa3oBU_fPl6ZX8GY17l_sao63pHuNox)"]},{"cell_type":"code","metadata":{"id":"p-Zv8ziv9RN4"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# set (hyper-)parameters\n","input_dim = 10\n","hidden1_dim = 20\n","p = 0.2\n","output_dim = 1\n","batch_size = 5\n","\n","# build a neural network\n","mlp1 = nn.Linear(input_dim, hidden1_dim)\n","relu = nn.ReLU()\n","dropout = nn.Dropout(p)\n","batchnorm = nn.BatchNorm1d(hidden1_dim)\n","mlp2 = nn.Linear(hidden1_dim, output_dim)\n","\n","# get an input data\n","inputs = torch.randn(batch_size, input_dim)\n","\n","# feed the data into the network layers\n","hidden1 = mlp1(inputs)\n","hidden2 = relu(hidden1)\n","hidden3 = dropout(hidden2)\n","hidden4 = batchnorm(hidden3)\n","outputs = mlp2(hidden4)\n","\n","# check output shapes\n","print(inputs.shape)\n","print(hidden1.shape)\n","print(hidden2.shape)\n","print(hidden3.shape)\n","print(hidden4.shape)\n","print(outputs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Me-LIkiI94Dr"},"source":["## `torch.nn.Sequential` makes your life more easier"]},{"cell_type":"code","metadata":{"id":"Z5bKL6YJ9-Ub"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# set (hyper-)parameters\n","input_dim = 10\n","hidden1_dim = 20\n","p = 0.2\n","output_dim = 1\n","batch_size = 5\n","\n","# build a neural network\n","my_network = nn.Sequential(\n","  nn.Linear(input_dim, hidden1_dim),\n","  nn.ReLU(),\n","  nn.Dropout(p),\n","  nn.BatchNorm1d(hidden1_dim),\n","  nn.Linear(hidden1_dim, output_dim),\n",")\n","\n","# get an (fake) input data\n","inputs = torch.randn(batch_size, input_dim)\n","\n","# feed the data into the network layers\n","outputs = my_network(inputs)\n","\n","# check output shapes\n","print(inputs.shape)\n","print(outputs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wLuQYCc7t2C4"},"source":["## The most standard way of building neural networks\n","- Modularize your network using `torch.nn.Module` **(highly-recommended)**"]},{"cell_type":"code","metadata":{"id":"kJL7VTuVvDrN"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","# pre-define your modularized network class\n","class MyNetwork(nn.Module):\n","  def __init__(self, input_dim, hidden1_dim, p, output_dim):\n","    super(MyNetwork, self).__init__()\n","    \n","    self.layers = nn.Sequential(\n","      nn.Linear(input_dim, hidden1_dim),\n","      nn.ReLU(),\n","      nn.Dropout(p),\n","      nn.BatchNorm1d(hidden1_dim),\n","      nn.Linear(hidden1_dim, output_dim),\n","    )\n","    \n","  def forward(self, x):\n","    prediction = self.layers(x)\n","    return prediction\n","  \n","  \n","# set (hyper-)parameters\n","input_dim = 10\n","hidden1_dim = 20\n","p = 0.2\n","output_dim = 1\n","batch_size = 5\n","\n","# build a neural network\n","my_network = MyNetwork(input_dim, hidden1_dim, p, output_dim)\n","\n","# get an (fake) input data\n","inputs = torch.randn(batch_size, input_dim)\n","\n","# feed the data into the network layers\n","outputs = my_network(inputs)\n","\n","# check output shapes\n","print(inputs.shape)\n","print(outputs.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SZcrPkAj1XDK"},"source":["## Modules for constructing optimizers\n","- `torch.optim`\n","- SGD : `torch.optim.SGD`\n","- ADAM : `torch.optim.Adam`\n","- RMSProp : `torch.optim.RMSprop`\n","\n","Please refer to [API](https://pytorch.org/docs/stable/optim.html) for more information on supported optimizers"]},{"cell_type":"markdown","metadata":{"id":"RPRV5tFcgpkC"},"source":["## Train a toy neural network regressor that learns a function y = 2x"]},{"cell_type":"code","metadata":{"id":"hk_NLilXpIG9"},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","# pre-define your modularized network class\n","class MyNetwork(nn.Module):\n","  def __init__(self, input_dim, hidden_dim, output_dim):\n","    super(MyNetwork, self).__init__()\n","    \n","    self.layers = nn.Sequential(\n","      nn.Linear(input_dim, hidden_dim),\n","      nn.ReLU(),\n","      nn.Linear(hidden_dim, hidden_dim),\n","      nn.ReLU(),\n","      nn.Linear(hidden_dim, hidden_dim),\n","      nn.ReLU(),\n","      nn.Linear(hidden_dim, output_dim),\n","    )\n","    \n","  def forward(self, x):\n","    prediction = self.layers(x)\n","    return prediction\n","  \n","  \n","# set (hyper-)parameters\n","input_dim = 1\n","hidden_dim = 100\n","output_dim = 1\n","batch_size = 100\n","learning_rate = 0.0001\n","max_iteration = 10000\n","\n","# build a neural network\n","my_network = MyNetwork(input_dim, hidden_dim, output_dim)\n","\n","# construct an optimizer\n","optimizer = optim.SGD(my_network.parameters(), lr=learning_rate)\n","\n","# start training\n","for i in range(max_iteration):\n","  # get an input data & label pair\n","  inputs = torch.randn(batch_size, input_dim)\n","  labels = inputs*2\n","\n","  # feed the data into the network layers\n","  predictions = my_network(inputs)\n","\n","  # calculate loss\n","  loss = F.mse_loss(predictions, labels)\n","  \n","  # flush previous gradients\n","  optimizer.zero_grad()\n","\n","  # backpropage loss and get gradients\n","  loss.backward()\n","  \n","  # update network parameters using gradients\n","  optimizer.step()\n","  \n","  if i % 1000 == 0:\n","    print('[{}] train loss : {:.3f}'.format(i, loss))\n","\n","\n","# test\n","test_inputs = torch.tensor([[0], [0.25], [0.5], [0.75], [1]])\n","test_labels = test_inputs*2\n","predictions = my_network(test_inputs)\n","\n","print('test inputs :\\n', test_inputs)\n","print('test labels :\\n', test_labels)\n","print('predictions :\\n', predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"5BuLdO20p22t"},"execution_count":null,"outputs":[]}]}