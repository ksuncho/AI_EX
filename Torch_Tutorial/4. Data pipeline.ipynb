{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4. Data pipeline.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-7hqNe0zNP-n"},"source":["Recommended materials\n","====\n","\n","1. Pytorch Official Tutorial \\[[Link](https://pytorch.org/tutorials/)\\]\n","2. DeepLearning Zero to All \\[[English](https://www.youtube.com/playlist?list=PLlMkM4tgfjnJ3I-dbhO9JTw7gNty6o_2m)\\] \\[[Korean](https://www.youtube.com/playlist?list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv)\\]\n","3. Neural Network Programming - Deep Learning with Pytorch \\[[English](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG)\\]"]},{"cell_type":"markdown","metadata":{"id":"qCCuAffjNZmI"},"source":["Data Loading and Pre-processing\n","===="]},{"cell_type":"markdown","metadata":{"id":"2ZV1jwEOBrT0"},"source":["## Common Data (Processing) Pipeline\n","\n","1. download or prepare data\n","2. make dataset using `torch.utils.data.Dataset`\n","3. (optional) construct data preprocessing code using `torchvision.transforms` if necessary\n","4. initialize dataloader using `torch.utils.data.DataLoader`"]},{"cell_type":"markdown","metadata":{"id":"AGzHovZ3AH4U"},"source":["## Preparing data\n","\n","Lets say our task is to learn a regressor that takes input **x** in range [0, 1] and predicts a function **y=2x**.  \n","Then, we need to prepare data that consists of input **x** and corresponding label **y** pairs.  \n","Now we are going to generate and save data."]},{"cell_type":"code","metadata":{"id":"J9ldof8_DIXT"},"source":["# mound google drive\n","from google.colab import drive\n","\n","drive.mount('/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cUODTMmvDTaw"},"source":["import os\n","import torch\n","\n","# make a directory to save our custom data\n","gdrive_root = '/gdrive/My Drive'\n","custom_data_dir = os.path.join(gdrive_root, 'my_data')\n","if not os.path.exists(custom_data_dir):\n","  os.makedirs(custom_data_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GqZTjSI9Dlqr"},"source":["num_samples = 10000\n","\n","# generate x in range [0, 1] using torch.rand()\n","x = torch.rand(num_samples)\n","\n","# generate y by multiplying 2 to x\n","y = 2*x\n","\n","# check data\n","for i in range(5):\n","  print(x[i:i+1], y[i:i+1])\n","\n","# aggregate x and y\n","data = {'inputs':x, 'labels':y}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TRRloXu1EMpf"},"source":["# now save data into data directory\n","data_path = os.path.join(custom_data_dir, 'data.pt')\n","torch.save(data, data_path)\n","\n","# check if is saved successfully\n","data_ = torch.load(data_path)\n","x_ = data['inputs']\n","y_ = data['labels']\n","for i in range(5):\n","  print(x_[i:i+1], y_[i:i+1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSjXIAfWFPya"},"source":["## Make Dataset\n","\n","We will use `torch.utils.data.Dataset` to make our custom dataset container.  \n","In this step, what you need to do is mostly three-fold:\n","1. Define `__init__` function. This function should receive the path of data, get data from that path, and keep them as attributes.\n","2. Define `__len__` function. This function should return the number of data\n","3. Define `__getitem__` function. This function should receive `idx` as an argument and return data specified by `idx`"]},{"cell_type":"code","metadata":{"id":"f58WVvYDFef0"},"source":["from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","  def __init__(self, root):\n","    data = torch.load(root)\n","    self.x = data['inputs']\n","    self.y = data['labels']\n","    self.num_samples = len(self.x)\n","    \n","  def __len__(self):\n","    return self.num_samples\n","  \n","  def __getitem__(self, idx):\n","    x = self.x[idx]\n","    y = self.y[idx]\n","    \n","    return x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8718Ws_rGELY"},"source":["# initialize dataset\n","dataset = CustomDataset(data_path)\n","\n","# when sample a data\n","print(dataset.__getitem__(0))\n","\n","# check the number of data\n","print(len(dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ebRmdIOB4Fg"},"source":["## Make DataLoader\n","\n","Now we are going to make dataloader using `torch.utils.data.DataLoader` which is very useful when we want to parse data fast, or make random batches of data."]},{"cell_type":"code","metadata":{"id":"sB7XUtzXIztn"},"source":["from torch.utils.data import DataLoader\n","\n","batch_size = 4\n","\n","# set `shuffle=True` to inject randomness in data-loading process\n","# set `num_workers` to more than 1 if you want to use multi-processing to speed up the dataloader\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nkraojcOJVtB"},"source":["# load data\n","for i, (inputs, labels) in enumerate(dataloader):\n","  print('[{}] batch_size:{} x:{} y:{}'.format(i, inputs.size(0), inputs, labels))\n","  \n","  # and then the training process goes like...\n","  \n","  # feed data into a neural network and get outputs\n","  # outputs = my_network(inputs)\n","  \n","  # calculate loss\n","  # loss = calc_loss(outputs, labels)\n","  \n","  # backpropagate loss\n","  # optimizer.zero_grad()\n","  # loss.backward()\n","  \n","  # update weights\n","  # optimizer.step()\n","  \n","  if i == 3:\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z6doqhC0KSwO"},"source":["## Data pre-processing\n","\n","Often we have to pre-process data before feeding it into the neural network.  \n","Lets consider the situation where now we need to learn **y=3x** function instead of **y=2x**.  \n","Without generating and saving data from scrach as we did above, we can get our desired data by adding pre-processing step in our dataset container.  \n","In particular, we just need to get **x** divided by 2 and multiplied by 3 to make **y=3x** and then return **x, y** in our dataset container"]},{"cell_type":"code","metadata":{"id":"EdmwDPmlNkSJ"},"source":["# add one more pre-processing step in our dataset container\n","from torch.utils.data import Dataset\n","\n","class CustomDataset(Dataset):\n","  def __init__(self, root, transform=None):\n","    data = torch.load(root)\n","    self.x = data['inputs']\n","    self.y = data['labels']\n","    self.transform = transform\n","    self.num_samples = len(self.x)\n","    \n","  def __len__(self):\n","    return self.num_samples\n","  \n","  def __getitem__(self, idx):\n","    x = self.x[idx]\n","    y = self.y[idx]\n","    \n","    # add one more pre-processing step here\n","    if self.transform is not None:\n","      y = self.transform(y)\n","    \n","    return x, y"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bsBohjN9MdSx"},"source":["from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","# make data pre-processor using torchvision.transforms\n","my_transform = transforms.Lambda(lambda x: x/2*3)\n","\n","batch_size = 4\n","dataset = CustomDataset(data_path, transform=my_transform)\n","dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","# load data\n","for i, (inputs, labels) in enumerate(dataloader):\n","  print('[{}] batch_size:{} x:{} y:{}'.format(i, inputs.size(0), inputs, labels))\n","  if i == 3:\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Odjmo23-N-Z3"},"source":[""],"execution_count":null,"outputs":[]}]}