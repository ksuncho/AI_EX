{"cells":[{"cell_type":"markdown","metadata":{"id":"szfSTP2MkCZs"},"source":["# Image-to-Image Translation : *pix2pix*"]},{"cell_type":"markdown","metadata":{"id":"DDiPyxsT-_ri"},"source":["## Download scripts & datasets"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"DyhwLuqZQAhk"},"outputs":[{"name":"stderr","output_type":"stream","text":["���� ������ �ùٸ��� �ʽ��ϴ�.\n","UsageError: Line magic function `%wget` not found.\n"]}],"source":["# Download dataset\n","%mkdir ./datasets\n","%wget -N http://efrosgans.eecs.berkeley.edu/pix2pix/datasets/facades.tar.gz -O ./datasets/facades.tar.gz\n","%mkdir -p ./datasets/facades/\n","%tar -zxvf ./datasets/facades.tar.gz -C ./datasets/\n"]},{"cell_type":"markdown","metadata":{"id":"wIjWfdCB8OF8"},"source":["## Open Tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZw_Td6m9A_9"},"outputs":[],"source":["%pip install tensorboardx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EmwO0T8R8RNG"},"outputs":[],"source":["# Check Tensorboard.\n","%mkdir runs\n","%ls runs\n","%load_ext tensorboard\n","%tensorboard --logdir runs --port 9999 --samples_per_plugin images=200"]},{"cell_type":"markdown","metadata":{"id":"RMDE0Hfs3IFN"},"source":["## Import modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKbJZOhJ3L0d"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","import os\n","from torch.utils.data import Dataset\n","import PIL\n","\n","from tensorboardX import SummaryWriter\n","from torchvision.utils import make_grid\n","import time\n","import functools\n"]},{"cell_type":"markdown","metadata":{"id":"dJjSXzlAmCOI"},"source":["## Prepare DataLoader for Facade dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5Fuxt5dP7IZ"},"outputs":[],"source":["# Fix manual seed.\n","torch.manual_seed(1234)\n","\n","# Set batch size.\n","BATCH_SIZE = 8\n","NUM_EXAMPLES = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0XsjfNBzc_id"},"outputs":[],"source":["# Custom Dataset \n","class CustomFacades(Dataset):\n","    def __init__(self, root, train=True, transform=None):\n","        self.root = root\n","        self.transform = transform       \n","        self.train = train\n","        self.dir = 'train' if train else 'test'\n","        self.len_train = 400\n","        self.len_test = 106\n","\n","    def __len__(self):\n","        if self.train:\n","            return self.len_train\n","        else:\n","            return self.len_test\n","\n","    def __getitem__(self, idx):\n","        data_idx = idx if self.train else idx + self.len_train\n","        X = PIL.Image.open(os.path.join(self.root, self.dir, '{}.jpg'.format(idx+1)))\n","        if self.transform is not None:\n","            X = self.transform(X)\n","        return X[..., 256:], X[..., :256]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uanjhhI5dIeH"},"outputs":[],"source":["# Prepare dataloader.\n","tf = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n","    ])\n","\n","# Train loader for training GAN\n","train_dataset = CustomFacades(root='./datasets/facades', train=True, \n","        transform=tf)\n","train_loader = DataLoader(dataset=train_dataset, num_workers=2, batch_size=BATCH_SIZE, shuffle=True)\n","\n","# Test loader for examining test samples\n","test_dataset = CustomFacades(root='./datasets/facades', train=False, transform=tf)\n","test_loader = DataLoader(dataset=test_dataset, num_workers=2, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"yf6CYjavmK_y"},"source":["## Define GAN Models"]},{"cell_type":"markdown","metadata":{"id":"GFVC5C4wmQ5k"},"source":["### Define Generator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iuiBN6NTFDgN"},"outputs":[],"source":["# Unet Generator for pix2pix model.\n","# https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix \n","class UnetGenerator(nn.Module):\n","    \"\"\"Create a Unet-based generator\"\"\"\n","\n","    def __init__(self, input_nc, output_nc, num_downs, ngf=64, norm_layer=nn.BatchNorm2d, use_dropout=False):\n","        \"\"\"Construct a Unet generator\n","        Parameters:\n","            input_nc (int)  -- the number of channels in input images\n","            output_nc (int) -- the number of channels in output images\n","            num_downs (int) -- the number of downsamplings in UNet. For example, # if |num_downs| == 7,\n","                                image of size 128x128 will become of size 1x1 # at the bottleneck\n","            ngf (int)       -- the number of filters in the last conv layer\n","            norm_layer      -- normalization layer\n","        We construct the U-Net from the innermost layer to the outermost layer.\n","        It is a recursive process.\n","        \"\"\"\n","        super(UnetGenerator, self).__init__()\n","        # construct unet structure\n","        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)  # add the innermost layer\n","        for i in range(num_downs - 5):          # add intermediate layers with ngf * 8 filters\n","            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n","        # gradually reduce the number of filters from ngf * 8 to ngf\n","        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n","        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n","        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n","        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)  # add the outermost layer\n","\n","    def forward(self, input):\n","        \"\"\"Standard forward\"\"\"\n","        return self.model(input)\n","\n","\n","class UnetSkipConnectionBlock(nn.Module):\n","    \"\"\"Defines the Unet submodule with skip connection.\n","        X -------------------identity----------------------\n","        |-- downsampling -- |submodule| -- upsampling --|\n","    \"\"\"\n","\n","    def __init__(self, outer_nc, inner_nc, input_nc=None,\n","                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n","        \"\"\"Construct a Unet submodule with skip connections.\n","        Parameters:\n","            outer_nc (int) -- the number of filters in the outer conv layer\n","            inner_nc (int) -- the number of filters in the inner conv layer\n","            input_nc (int) -- the number of channels in input images/features\n","            submodule (UnetSkipConnectionBlock) -- previously defined submodules\n","            outermost (bool)    -- if this module is the outermost module\n","            innermost (bool)    -- if this module is the innermost module\n","            norm_layer          -- normalization layer\n","            use_dropout (bool)  -- if use dropout layers.\n","        \"\"\"\n","        super(UnetSkipConnectionBlock, self).__init__()\n","        self.outermost = outermost\n","        if type(norm_layer) == functools.partial:\n","            use_bias = norm_layer.func == nn.InstanceNorm2d\n","        else:\n","            use_bias = norm_layer == nn.InstanceNorm2d\n","        if input_nc is None:\n","            input_nc = outer_nc\n","        downconv = nn.Conv2d(input_nc, inner_nc, kernel_size=4,\n","                             stride=2, padding=1, bias=use_bias)\n","        downrelu = nn.LeakyReLU(0.2, True)\n","        downnorm = norm_layer(inner_nc)\n","        uprelu = nn.ReLU(True)\n","        upnorm = norm_layer(outer_nc)\n","\n","        if outermost:\n","            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n","                                        kernel_size=4, stride=2,\n","                                        padding=1)\n","            down = [downconv]\n","            up = [uprelu, upconv, nn.Tanh()]\n","            model = down + [submodule] + up\n","        elif innermost:\n","            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n","                                        kernel_size=4, stride=2,\n","                                        padding=1, bias=use_bias)\n","            down = [downrelu, downconv]\n","            up = [uprelu, upconv, upnorm]\n","            model = down + up\n","        else:\n","            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n","                                        kernel_size=4, stride=2,\n","                                        padding=1, bias=use_bias)\n","            down = [downrelu, downconv, downnorm]\n","            up = [uprelu, upconv, upnorm]\n","\n","            if use_dropout:\n","                model = down + [submodule] + up + [nn.Dropout(0.5)]\n","            else:\n","                model = down + [submodule] + up\n","\n","        self.model = nn.Sequential(*model)\n","\n","    def forward(self, x):\n","        if self.outermost:\n","            return self.model(x)\n","        else:   # add skip connections\n","            return torch.cat([x, self.model(x)], 1)\n"]},{"cell_type":"markdown","metadata":{"id":"ajYUrgp0mUt8"},"source":["### Define Discriminator"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5upJT6CemOz6"},"outputs":[],"source":["# Unet Discriminator for pix2pix model.\n","# https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix \n","class NLayerDiscriminator(nn.Module):\n","    \"\"\"Defines a PatchGAN discriminator\"\"\"\n","\n","    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n","        \"\"\"Construct a PatchGAN discriminator\n","        Parameters:\n","            input_nc (int)  -- the number of channels in input images\n","            ndf (int)       -- the number of filters in the last conv layer\n","            n_layers (int)  -- the number of conv layers in the discriminator\n","            norm_layer      -- normalization layer\n","        \"\"\"\n","        super(NLayerDiscriminator, self).__init__()\n","        if type(norm_layer) == functools.partial:  # no need to use bias as BatchNorm2d has affine parameters\n","            use_bias = norm_layer.func == nn.InstanceNorm2d\n","        else:\n","            use_bias = norm_layer == nn.InstanceNorm2d\n","\n","        kw = 4\n","        padw = 1\n","        sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n","        nf_mult = 1\n","        nf_mult_prev = 1\n","        for n in range(1, n_layers):  # gradually increase the number of filters\n","            nf_mult_prev = nf_mult\n","            nf_mult = min(2 ** n, 8)\n","            sequence += [\n","                nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n","                norm_layer(ndf * nf_mult),\n","                nn.LeakyReLU(0.2, True)\n","            ]\n","\n","        nf_mult_prev = nf_mult\n","        nf_mult = min(2 ** n_layers, 8)\n","        sequence += [\n","            nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n","            norm_layer(ndf * nf_mult),\n","            nn.LeakyReLU(0.2, True)\n","        ]\n","\n","        sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]  # output 1 channel prediction map\n","        self.model = nn.Sequential(*sequence)\n","\n","    def forward(self, input):\n","        \"\"\"Standard forward.\"\"\"\n","        return self.model(input)"]},{"cell_type":"markdown","metadata":{"id":"z7yQUvj2rMLU"},"source":["## Prepare GAN model and initialize the weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Irabx2XtoRhY"},"outputs":[],"source":["# Weight initialization function. \n","def weights_init(net):\n","    for m in net.modules():\n","        if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Linear):\n","            # m.weight.data.normal_(1.0, 0.2)\n","            nn.init.xavier_normal_(m.weight.data)\n","            if m.bias is not None:\n","                m.bias.data.zero_()\n","        elif isinstance(m, nn.BatchNorm2d):\n","            m.weight.data.normal_(1.0, 0.2)\n","            m.bias.data.zero_()\n","\n","# Define GAN model.\n","G = UnetGenerator(input_nc=3, output_nc=3, num_downs=8).cuda()\n","D = NLayerDiscriminator(input_nc=3+3, ndf=64, n_layers=3).cuda()\n","\n","# Weight initialization \n","G.apply(weights_init)\n","D.apply(weights_init)"]},{"cell_type":"markdown","metadata":{"id":"MhfKpgHmnQz_"},"source":["## Start training GAN (Expected: 1min/epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJWTZUxxeQ2I"},"outputs":[],"source":["# Hyperparameters. \n","# ====== You don't need to change here ===== #\n","EPOCHS = 200\n","Z_DIM = 64\n","LAMBDA_L1 = 100\n","# ========================================== #\n","\n","# Logger for tensorboard.\n","logger = SummaryWriter()\n","\n","# GT labels for calculating binary cross entropy loss. \n","real_label = torch.ones(size=(BATCH_SIZE,1)).cuda()\n","fake_label = torch.zeros(size=(BATCH_SIZE,1)).cuda()\n","\n","# Criterion for binary cross entropy loss\n","BCE_criterion = torch.nn.BCEWithLogitsLoss()\n","\n","# Define optimizer. Here we use Adam optimizer. \n","optimizer_G = torch.optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\n","optimizer_D = torch.optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\n","\n","iterations = 0\n","\n","for epoch in range(EPOCHS):\n","    # Set both G&D train modes.\n","    G.train()\n","    D.train()\n","\n","    # For logging in tensorboard\n","    loss_G_total, loss_D_total = 0., 0.\n","    loss_G_sub_total, loss_D_sub_total = 0., 0.\n","\n","    for batch_idx, (real_A, real_B) in enumerate(train_loader):\n","        t1 = time.time()\n","        real_A = real_A.cuda()\n","        real_B = real_B.cuda()\n","\n","        # ============================================================ #\n","        # TODO : Fill the part for updating D&G.\n","        #  * you can generate fake_B using Generator(G).\n","        #   ex) fake_B = G(real_A)\n","        #  * first compute loss and back propgation with optimizers.\n","        #  * Note that you should compute L1 loss to when computing \n","        #    generator loss. \n","        # ============================================================ #\n","\n","        # ================= Update D ================== # \n","\n","        # Fill here. \n","        # First compute loss_D \n","        # Then update the network with loss_D using optimizer_D\n","        \n","        # ================= Update G ================== # \n","\n","        # Fill here \n","        # First compute loss_G \n","        # Then update the network with loss_G using optimizer_G.\n","        # You should also consider L1 loss between real_B, fake_B.\n","\n","        # ======================== End of TODO ======================== #\n","\n","        # For logging\n","        loss_D_total += loss_D.item()\n","        loss_G_total += loss_G.item()\n","        \n","        loss_G_sub_total += loss_G.item()\n","        loss_D_sub_total += loss_D.item()\n","\n","        # print current states\n","        print_freq = 10\n","        if batch_idx % print_freq  == 0 and batch_idx > 0:\n","            print('Epoch : {} || {}/{} || loss_G={:.3f} loss_D={:.3f} time={:.3f} s/iter'.format(\n","                epoch, batch_idx, len(train_loader), \n","                loss_G_sub_total/print_freq, loss_D_sub_total/print_freq, \n","                time.time()-t1\n","            ))\n","            # ================= Genearte example samples ================== # \n","            for bi, (real_A_test, real_B_test) in enumerate(test_loader):\n","                if bi>0:\n","                    break\n","                real_A_test = real_A_test[:NUM_EXAMPLES].cuda()\n","                real_B_test = real_B_test[:NUM_EXAMPLES].cuda()\n","                with torch.no_grad():\n","                    fake_B_test = G(real_A_test)\n","                    fake_B_test = fake_B_test[:NUM_EXAMPLES]\n","\n","                real_A_samples = (real_A_test + 1)/2\n","                real_B_samples = (real_B_test + 1)/2\n","                fake_B_samples = (fake_B_test + 1)/2\n","                examples = torch.cat((real_A_samples, fake_B_samples, real_B_samples), dim=0)\n","                examples = make_grid(examples, nrow=NUM_EXAMPLES)\n","                \n","                # log images\n","                logger.add_image('Generated_pairs', examples, iterations)\n","\n","            iterations += 1\n","            loss_G_sub_total = 0\n","            loss_D_sub_total = 0\n","\n","    loss_G_total /= len(train_loader)\n","    loss_D_total /= len(train_loader)\n","    \n","    # logging on tensorboard\n","    logger.add_scalar('loss_G', loss_G_total, epoch)\n","    logger.add_scalar('loss_D', loss_D_total, epoch)\n","\n","    # print current states\n","    print('Epoch : {} >> AVG loss : loss_G={:.3f} loss_D={:.3f}'.format(\n","        epoch, loss_G_total, loss_D_total\n","    ))\n"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"(Lab 2) pix2pix.ipynb","provenance":[{"file_id":"1J7UQJ9T5xs6FiJHsTRq0s25loUzvMm0t","timestamp":1629875109119}]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"bf789d3fe2e48003609d2b27099c8c5750f1d9c6ed54a4f20100144dcd5707b9"}}},"nbformat":4,"nbformat_minor":0}
