{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5. Train and Test a simple MLP-based MNIST classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PRqPMAzzNipD"},"source":["Recommended materials\n","====\n","\n","1. Pytorch Official Tutorial \\[[Link](https://pytorch.org/tutorials/)\\]\n","2. DeepLearning Zero to All \\[[English](https://www.youtube.com/playlist?list=PLlMkM4tgfjnJ3I-dbhO9JTw7gNty6o_2m)\\] \\[[Korean](https://www.youtube.com/playlist?list=PLQ28Nx3M4JrhkqBVIXg-i5_CVVoS1UzAv)\\]\n","3. Neural Network Programming - Deep Learning with Pytorch \\[[English](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG)\\]"]},{"cell_type":"markdown","metadata":{"id":"d6E8jHQ7qQFk"},"source":["Pipeline for training and testing a simple MLP MNIST classifier\n","===="]},{"cell_type":"markdown","metadata":{"id":"RO1mgGV_uOIK"},"source":["## Step 1: Connect to your Google Drive\n","\n","It is required if you want to save checkpoints and load them later on"]},{"cell_type":"code","metadata":{"id":"cLth6ZfXuSGT"},"source":["from google.colab import drive\n","\n","drive.mount('/gdrive')\n","gdrive_root = '/gdrive/My Drive'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RYwUwGf8qW1U"},"source":["## Step 2: Import modules"]},{"cell_type":"code","metadata":{"id":"3UtshANjqpy4"},"source":["import os\n","\n","import torch\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","from torch.utils.tensorboard import SummaryWriter\n","import datetime\n","\n","torch.manual_seed(470)\n","torch.cuda.manual_seed(470)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0iJ-Q6sbq8c3"},"source":["## Step 3: Configure the experiments"]},{"cell_type":"code","metadata":{"id":"fA5jAy7Wq-E2"},"source":["# training & optimization hyper-parameters\n","max_epoch = 10\n","learning_rate = 0.0001\n","batch_size = 200\n","device = 'cuda'\n","\n","# model hyper-parameters\n","input_dim = 784 # 28x28=784\n","hidden_dim = 512\n","output_dim = 10\n","\n","# initialize tensorboard for visualization\n","log_dir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n","writer = SummaryWriter(log_dir)\n","%load_ext tensorboard\n","%tensorboard --logdir $log_dir"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2tZt60aMrQ1g"},"source":["## Step 4: Construct data pipeline\n","\n","**`torchvision.datasets.MNIST`** will automatically construct **`MNIST`** dataset."]},{"cell_type":"code","metadata":{"id":"aHbtV46LrXOF"},"source":["data_dir = os.path.join(gdrive_root, 'my_data')\n","\n","transform = transforms.ToTensor()\n","\n","train_dataset = MNIST(data_dir, train=True, download=True, transform=transform)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n","\n","test_dataset = MNIST(data_dir, train=False, download=True, transform=transform)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6G_dWd-6rwWb"},"source":["## Step 5: Construct a neural network builder"]},{"cell_type":"code","metadata":{"id":"FX_wne0Vr1E5"},"source":["class MyClassifier(nn.Module):\n","  def __init__(self, input_dim=784, hidden_dim=512, output_dim=10):\n","    super(MyClassifier, self).__init__()\n","    self.layers = nn.Sequential(\n","      nn.Linear(input_dim, hidden_dim),\n","      nn.ReLU(),\n","      nn.Linear(hidden_dim, hidden_dim),\n","      nn.ReLU(),\n","      nn.Linear(hidden_dim, hidden_dim),\n","      nn.ReLU(),\n","      nn.Linear(hidden_dim, output_dim),\n","    )\n","    \n","  def forward(self, x):\n","    batch_size = x.size(0)\n","    x = x.view(batch_size, -1)\n","    outputs = self.layers(x)\n","    return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YpA3xhjMspvA"},"source":["## Step 6: Initialize the network and optimizer"]},{"cell_type":"code","metadata":{"id":"XP111gW0s8aH"},"source":["my_classifier = MyClassifier(input_dim, hidden_dim, output_dim)\n","my_classifier = my_classifier.to(device)\n","\n","optimizer = optim.Adam(my_classifier.parameters(), lr=learning_rate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8lAQeXmjsILS"},"source":["## Step 7: Load pre-trained weights if exist"]},{"cell_type":"code","metadata":{"id":"hFLNZxaBsHUl"},"source":["ckpt_dir = os.path.join(gdrive_root, 'checkpoints')\n","if not os.path.exists(ckpt_dir):\n","  os.makedirs(ckpt_dir)\n","  \n","best_acc = 0.\n","ckpt_path = os.path.join(ckpt_dir, 'lastest.pt')\n","if os.path.exists(ckpt_path):\n","  ckpt = torch.load(ckpt_path)\n","  try:\n","    my_classifier.load_state_dict(ckpt['my_classifier'])\n","    optimizer.load_state_dict(ckpt['optimizer'])\n","    best_acc = ckpt['best_acc']\n","  except RuntimeError as e:\n","      print('wrong checkpoint')\n","  else:    \n","    print('checkpoint is loaded !')\n","    print('current best accuracy : %.2f' % best_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z1t7n6yttNEc"},"source":["## Step 8: Train the network\n","\n","Note : It would be better to save checkpoints periodically, otherwise you'll lose everything you've trained if the session is recycled."]},{"cell_type":"code","metadata":{"id":"9vczdKbytV38"},"source":["it = 0\n","train_losses = []\n","test_losses = []\n","for epoch in range(max_epoch):\n","  # train phase\n","  # Note: Behaviours of some layers/modules, such as dropout, batchnorm, etc., are different (or should be treated differently) depending on whether the phase is in train or test\n","  #       For example, dropout modules turn off some activations with probability p in training time, but not in test time.\n","  #       However, our network \"my_classifier\" does not know which phase is under-going, and we need to give the network a signal to handle this issue.\n","  #       Fortuntely, Pytorch provides us the utility functions for this, which are `.train()` and `.eval()`\n","  my_classifier.train()\n","  for inputs, labels in train_dataloader:\n","    it += 1\n","    \n","    # load data to the GPU.\n","    inputs = inputs.to(device)\n","    labels = labels.to(device)\n","    \n","    # feed data into the network and get outputs.\n","    logits = my_classifier(inputs)\n","    \n","    # calculate loss\n","    # Note: `F.cross_entropy` function receives logits, or pre-softmax outputs, rather than final probability scores.\n","    loss = F.cross_entropy(logits, labels)\n","    \n","    # Note: You should flush out gradients computed at the previous step before computing gradients at the current step. \n","    #       Otherwise, gradients will accumulate.\n","    optimizer.zero_grad()\n","    \n","    # backprogate loss.\n","    loss.backward()\n","    \n","    # update the weights in the network.\n","    optimizer.step()\n","    \n","    # calculate accuracy.\n","    acc = (logits.argmax(dim=1) == labels).float().mean()\n","    \n","    if it % 200 == 0:\n","      writer.add_scalars('Loss', {'train_loss': loss.item()}, it)\n","      print('[epoch:{}, iteration:{}] train loss : {:.4f} train accuracy : {:.4f}'.format(epoch, it, loss.item(), acc.item()))\n","    \n","  # save losses in a list so that we can visualize them later.\n","  train_losses.append(loss.item())  \n","    \n","  # test phase\n","  n = 0.\n","  test_loss = 0.\n","  test_acc = 0.\n","  my_classifier.eval()\n","  for test_inputs, test_labels in test_dataloader:\n","    test_inputs = test_inputs.to(device)\n","    test_labels = test_labels.to(device)\n","    \n","    logits = my_classifier(test_inputs)\n","    test_loss += F.cross_entropy(logits, test_labels, reduction='sum')\n","    test_acc += (logits.argmax(dim=1) == test_labels).float().sum()\n","    n += test_inputs.size(0)\n","    \n","  test_loss /= n\n","  test_acc /= n\n","  test_losses.append(test_loss.item())\n","  writer.add_scalars('Loss', {'test_loss': test_loss.item()}, it)\n","  print('[epoch:{}, iteration:{}] test_loss : {:.4f} test accuracy : {:.4f}'.format(epoch, it, test_loss.item(), test_acc.item())) \n","  \n","  writer.flush()\n","\n","  # save checkpoint whenever there is improvement in performance\n","  if test_acc > best_acc:\n","    best_acc = test_acc\n","    # Note: optimizer also has states ! don't forget to save them as well.\n","    ckpt = {'my_classifier':my_classifier.state_dict(),\n","            'optimizer':optimizer.state_dict(),\n","            'best_acc':best_acc}\n","    torch.save(ckpt, ckpt_path)\n","    print('checkpoint is saved !')\n","    \n","writer.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ECu3yS0OvfoR"},"source":["## Step 9: Visualize and analyze the results"]},{"cell_type":"code","metadata":{"id":"G89sqVp-vLRy"},"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(train_losses, label='train loss')\n","plt.plot(test_losses, label='test loss')\n","plt.legend()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KHjD9SGrvhzc"},"source":["import random\n","from PIL import Image\n","\n","my_classifier.eval()\n","\n","num_test_samples = len(test_dataset)\n","random_idx = random.randint(0, num_test_samples)\n","\n","topil = transforms.transforms.ToPILImage()\n","test_input, test_label = test_dataset.__getitem__(random_idx)\n","test_prediction = F.softmax(my_classifier(test_input.unsqueeze(0).to(device)), dim=1).argmax().item()\n","print('label : %i' % test_label)\n","print('prediction : %i' % test_prediction)\n","\n","test_image = topil(test_input)\n","test_image.resize((128, 128))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DkWlGU8CttiL"},"source":["## Next step: Try and test your own network on Fashion-MNIST dataset\n","\n","[link](https://drive.google.com/open?id=1_nMBHIGOMQLea6q79AC9JMwpFWesMtKv)"]},{"cell_type":"code","source":[""],"metadata":{"id":"AD2uBnSMqd1z"},"execution_count":null,"outputs":[]}]}