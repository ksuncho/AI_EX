{"cells":[{"cell_type":"markdown","metadata":{"id":"umzZEZF2B2Z2"},"source":["### Imports"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"QMyjiTD0B2Z3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python version:  3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n","Pytorch version:  1.12.0+cu113\n","GPU available: True\n","current GPU index: 0\n","current GPU card name: GeForce RTX 2070 Super with Max-Q Design\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from PIL import Image\n","\n","# Other dependencies\n","import random\n","import sys\n","import os\n","import tqdm\n","import time\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","print('Python version: ', sys.version)\n","print('Pytorch version: ', torch.__version__)\n","\n","print(\"GPU available: {}\".format(torch.cuda.is_available()))\n","print(\"current GPU index: {}\".format(torch.cuda.current_device()))\n","print(\"current GPU card name: {}\".format(torch.cuda.get_device_name(0)))"]},{"cell_type":"markdown","metadata":{"id":"10EEnZ8dB2aE"},"source":["#### Model definition\n","\n","\n","> Our model follows the architecture which has 3 modules with a 3 × 3 convolutions and 64 filters, followed by\n","batch normalization (Ioffe & Szegedy, 2015), a ReLU nonlinearity, and 2 × 2 max-pooling. "]},{"cell_type":"code","execution_count":8,"metadata":{"id":"jevbblhFB2aF"},"outputs":[],"source":["# TODO 1. build your model following the instruction above.\n","# Note that, the size of inputs will be (32, 32)\n","class Net(nn.Module):\n","  def __init__(self, nclasses):\n","    super(Net, self).__init__()\n","    self.conv1 = nn.Conv2d(3, 64, 3)\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.act1 = nn.ReLU()\n","    self.max1 = nn.MaxPool2d(2)\n","\n","    self.conv2 = nn.Conv2d(64, 64, 3)\n","    self.bn2 = nn.BatchNorm2d(64)\n","    self.act2 = nn.ReLU()\n","    self.max2 = nn.MaxPool2d(2)\n","\n","    self.conv3 = nn.Conv2d(64, 64, 3)\n","    self.bn3 = nn.BatchNorm2d(64)\n","    self.act3 = nn.ReLU()\n","    self.max3 = nn.MaxPool2d(2)\n","\n","    self.flatten = nn.Flatten()\n","    self.fc = nn.Linear(256, nclasses)     \n","\n","  def forward(self, img):\n","    x = self.conv1(img)\n","    x = self.bn1(x)\n","    x = self.act1(x)\n","    x = self.max1(x)\n","\n","    x = self.conv2(x)\n","    x = self.bn2(x)\n","    x = self.act2(x)\n","    x = self.max2(x)\n","\n","    x = self.conv3(x)\n","    x = self.bn3(x)\n","    x = self.act3(x)\n","    x = self.max3(x)\n","\n","    x = self.flatten(x)\n","    x = self.fc(x)\n","    return x"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"vPCbH_jX3gM9"},"outputs":[{"data":{"text/plain":["tensor([[-0.9533, -0.3489, -0.2274,  0.2298,  0.5392]],\n","       grad_fn=<AddmmBackward0>)"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# test if it works\n","net = Net(5)\n","img = torch.randn((1, 3, 32, 32))\n","net(img)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"vs5FjD8u4vEo"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to dataset/cifar10\\cifar-10-python.tar.gz\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"490339ff0e2c47efbd6b5954f291bec7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/170498071 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Extracting dataset/cifar10\\cifar-10-python.tar.gz to dataset/cifar10\n","Files already downloaded and verified\n"]}],"source":["# prepare everything needed for training the CNN model\n","# load the CIFAR10 dataset from the torchvision package\n","train_transform = transforms.Compose([\n","                                      transforms.RandomHorizontalFlip(),\n","                                      transforms.ToTensor(),\n","                                      ])\n","test_transform = transforms.Compose([\n","                                     transforms.ToTensor(),\n","                                     ])\n","\n","train_dataset = torchvision.datasets.CIFAR10(root='dataset/cifar10', train=True, download=True, transform=train_transform)\n","test_dataset = torchvision.datasets.CIFAR10(root='dataset/cifar10', train=False, download=True, transform=test_transform)\n","\n","# get the dataloader\n","train_dataloader = DataLoader(train_dataset, batch_size=256, drop_last=True, shuffle=True)\n","test_dataloader = DataLoader(test_dataset, batch_size=128, drop_last=False, shuffle=False)\n","\n","# instantiate the model & move to GPU\n","model = Net(nclasses=10)\n","model.to(\"cuda:0\")\n","\n","criterion = nn.CrossEntropyLoss() # instantiate the loss (criterion)\n","criterion.to('cuda:0') # move to GPU\n","\n","# get the optimizer to train the model\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 180, 190], gamma=0.1)\n","#=================================================== "]},{"cell_type":"code","execution_count":11,"metadata":{"id":"8hoBrBsE48U5"},"outputs":[],"source":["def train(dataloader, model, criterion, optimizer):\n","  model.train()\n","  total_loss = 0\n","  total_acc = 0\n","  n = 0\n","  for x, y in dataloader:#tqdm.notebook.tqdm(dataloader, desc='train', leave=False):\n","    optimizer.zero_grad() \n","    x, y = x.cuda(), y.cuda()\n","    logits = model(x)\n","    loss = criterion(logits, y)\n","    loss.backward()\n","    optimizer.step()\n","\n","    pred = torch.argmax(logits, dim=1) # (# minibatch, #class)\n","    acc = torch.sum(pred == y)\n","    \n","    total_loss += loss.item() * x.shape[0]\n","    total_acc += acc.item()\n","    n += x.shape[0]\n","\n","  return total_loss / n, total_acc / n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"hS6ixdib8N02"},"outputs":[],"source":["@torch.no_grad()\n","def test(dataloader, model, criterion):\n","  model.eval()\n","  total_loss = 0\n","  total_acc = 0\n","  n = 0\n","  for x, y in dataloader:#tqdm.notebook.tqdm(dataloader, desc='test', leave=False):\n","    x, y = x.cuda(), y.cuda()\n","    logits = model(x)\n","    loss = criterion(logits, y)\n","\n","    pred = torch.argmax(logits, dim=1)\n","    acc = torch.sum(pred == y)\n","\n","    total_loss += loss.item() * x.shape[0]\n","    total_acc += acc.item()\n","    n += x.shape[0]\n","\n","  return total_loss / n, total_acc / n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"HIZX1A5C5hTo"},"outputs":[{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-733e2e205b7d2350\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-733e2e205b7d2350\");\n","          const url = new URL(\"/\", window.location);\n","          const port = 6006;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["%load_ext tensorboard\n","%tensorboard --logdir runs"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"-1Ssk8lo8Go0"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"969926d4d2cb430c9cae77d7501867b1","version_major":2,"version_minor":0},"text/plain":["EPOCH:   0%|          | 0/200 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# train the model for 200 epochs\n","writer = SummaryWriter('runs/cifar10')\n","for epc in tqdm.notebook.trange(200, desc='EPOCH'):\n","  tr_loss, tr_acc = train(train_dataloader, model, criterion, optimizer)\n","  te_loss, te_acc = test(test_dataloader, model, criterion)\n","\n","  writer.add_scalar('train/loss', tr_loss, epc)\n","  writer.add_scalar('train/acc', tr_acc, epc)\n","  writer.add_scalar('test/loss', te_loss, epc)\n","  writer.add_scalar('test/acc', te_acc, epc)\n","  writer.flush()\n","\n","  scheduler.step()\n","  \n","writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CIP1Dc716ZG"},"outputs":[],"source":["# train CIFAR100 with the ImageNet pretrained resnet34 model provided by PyTorch\n","#================ YOUR CODE HERE ===================\n","# load the CIFAR100 dataset from the torchvision package\n","\n","# get the dataloader\n","\n","# instantiate the model & move to GPU\n","\n","# get the optimizer to train the model\n","\n","# SET EPOCHS\n","EPOCHS = \n","writer = SummaryWriter('runs/cifar100')\n","for epc in tqdm.notebook.trange(EPOCHS, desc='EPOCH'):\n","  tr_loss, tr_acc = train(train_dataloader, model, criterion, optimizer)\n","  te_loss, te_acc = test(test_dataloader, model, criterion)\n","\n","  writer.add_scalar('train/loss', tr_loss, epc)\n","  writer.add_scalar('train/acc', tr_acc, epc)\n","  writer.add_scalar('test/loss', te_loss, epc)\n","  writer.add_scalar('test/acc', te_acc, epc)\n","  writer.flush()\n","\n","  scheduler.step()\n","  \n","writer.close()\n","\n","#=================================================== "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RrJQcTrM7nCT"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"[Day 4-2] PyTorch Training.ipynb","provenance":[{"file_id":"https://github.com/mari-linhares/tensorflow-maml/blob/master/maml.ipynb","timestamp":1606711618083}]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10"},"vscode":{"interpreter":{"hash":"bf789d3fe2e48003609d2b27099c8c5750f1d9c6ed54a4f20100144dcd5707b9"}}},"nbformat":4,"nbformat_minor":0}
