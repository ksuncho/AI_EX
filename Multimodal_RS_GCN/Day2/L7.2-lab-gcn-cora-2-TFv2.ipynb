{"cells":[{"cell_type":"markdown","metadata":{"id":"0fl-dVx0piOY"},"source":["# Graph Convolutional Network - Lab 2"]},{"cell_type":"markdown","metadata":{"id":"TbKUB8RkpiPK"},"source":["## Data Preprocessing"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2679,"status":"ok","timestamp":1659589539233,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"8Mhju9MCJlYl","outputId":"da420500-b00f-4810-a35c-8601a798160d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# For colab users\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":2412,"status":"ok","timestamp":1659589541637,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"dGT8yJztpiPL"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"elapsed":613,"status":"ok","timestamp":1659589542246,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"f8Hp_6QFpiPN","outputId":"b9987fad-20fd-4c7e-d885-8e6d0351ece3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>1425</th>\n","      <th>1426</th>\n","      <th>1427</th>\n","      <th>1428</th>\n","      <th>1429</th>\n","      <th>1430</th>\n","      <th>1431</th>\n","      <th>1432</th>\n","      <th>1433</th>\n","      <th>1434</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>31336</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Neural_Networks</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1061127</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Rule_Learning</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1106406</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Reinforcement_Learning</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>13195</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Reinforcement_Learning</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>37879</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Probabilistic_Methods</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 1435 columns</p>\n","</div>"],"text/plain":["      0     1     2     3     4     5     6     7     8     9     ...  1425  \\\n","0    31336     0     0     0     0     0     0     0     0     0  ...     0   \n","1  1061127     0     0     0     0     0     0     0     0     0  ...     0   \n","2  1106406     0     0     0     0     0     0     0     0     0  ...     0   \n","3    13195     0     0     0     0     0     0     0     0     0  ...     0   \n","4    37879     0     0     0     0     0     0     0     0     0  ...     0   \n","\n","   1426  1427  1428  1429  1430  1431  1432  1433                    1434  \n","0     0     1     0     0     0     0     0     0         Neural_Networks  \n","1     1     0     0     0     0     0     0     0           Rule_Learning  \n","2     0     0     0     0     0     0     0     0  Reinforcement_Learning  \n","3     0     0     0     0     0     0     0     0  Reinforcement_Learning  \n","4     0     0     0     0     0     0     0     0   Probabilistic_Methods  \n","\n","[5 rows x 1435 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#path = '/content/drive/MyDrive/TA/NPEX4기/0804/cora/cora.content'\n","path = './cora/cora.content'\n","cora_content = pd.read_csv(path, sep='\\t', header=None)\n","cora_content.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1659589542247,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"Wb-OJssMpiPO","outputId":"3fabbf14-0a6a-463c-de1a-7c6ff861ad17","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Case_Based 298\n","Genetic_Algorithms 418\n","Neural_Networks 818\n","Probabilistic_Methods 426\n","Reinforcement_Learning 217\n","Rule_Learning 180\n","Theory 351\n"]}],"source":["ids = cora_content[0].values # paper(node) ids\n","vecs = cora_content.iloc[:, 1:1434].values # node features\n","labels = cora_content[1434].values # node labels\n","\n","for l in np.unique(labels):\n","    print(l, labels[labels == l].shape[0])"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1659589542248,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"Q9-yHQg3piPP"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","\n","# node label one hot encoding\n","labels_onehot = LabelEncoder().fit_transform(labels)\n","labels_onehot = np.expand_dims(labels_onehot, axis=1)\n","labels_onehot = OneHotEncoder().fit_transform(labels_onehot)\n","labels_onehot = labels_onehot.toarray()"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1659589542249,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"pmIAJ2P3BXK5","outputId":"e2f2e87c-1be3-485f-9fab-0637a8654972"},"outputs":[{"name":"stdout","output_type":"stream","text":["   Case_Based  Genetic_Algorithms  Neural_Networks  Probabilistic_Methods  \\\n","0           0                   0                1                      0   \n","1           0                   0                0                      0   \n","2           0                   0                0                      0   \n","3           0                   0                0                      0   \n","4           0                   0                0                      1   \n","\n","   Reinforcement_Learning  Rule_Learning  Theory  \n","0                       0              0       0  \n","1                       0              1       0  \n","2                       1              0       0  \n","3                       1              0       0  \n","4                       0              0       0  \n","[[0 0 1 0 0 0 0]\n"," [0 0 0 0 0 1 0]\n"," [0 0 0 0 1 0 0]\n"," [0 0 0 0 1 0 0]\n"," [0 0 0 1 0 0 0]]\n"]}],"source":["# Generate Onehot vectors using pd.get_dummies\n","import pandas as pd\n","labels_onehot_2 = pd.get_dummies(labels)\n","print(labels_onehot_2[:5])\n","labels_onehot_2 = labels_onehot_2.values\n","print(labels_onehot_2[:5])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1659589542249,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"TjqYAsbYpiPQ","outputId":"098f9656-3da1-483d-8667-53a4f98e222a"},"outputs":[{"name":"stdout","output_type":"stream","text":["(2708,) (2708, 1433) (2708, 7)\n"]}],"source":["inds = np.arange(ids.shape[0]) # use index at identifying each node\n","x = vecs\n","y = labels_onehot\n","print(ids.shape, x.shape, y.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1659589542250,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"SGD3rJeopiPR","outputId":"6e756a10-6dea-4c8e-916d-8b81bae6b5c8"},"outputs":[{"name":"stdout","output_type":"stream","text":["(56,) (14,) (700,)\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","num_classes = 7\n","num_per_train = 10\n","num_per_test = 100\n","\n","y_train, y_test, idx_train, idx_test = train_test_split(\n","    y, inds, stratify=y, random_state=42,\n","    train_size=num_classes * num_per_train,\n","    test_size=num_classes * num_per_test)\n","\n","idx_train, idx_valid = train_test_split(\n","    idx_train, stratify=y_train, random_state=42,\n","    train_size=int(num_classes * num_per_train * 0.8),\n","    test_size=int(num_classes * num_per_train * 0.2))\n","\n","print(idx_train.shape, idx_valid.shape, idx_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"aR7XGTAbpiPS"},"source":["## Skeleton Codes"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1659589542250,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"BI2-AP75piPS"},"outputs":[],"source":["from tensorflow import sparse\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import Model"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1659589542251,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"RVdRyLmwpiPT"},"outputs":[],"source":["class GCN2(Model):\n","    def __init__(self, indices, values, input_dim=1433, \n","                 hid_dim=64, num_classes=7, num_nodes=2708,\n","                num_layers=2):\n","        super(GCN2, self).__init__()\n","        \n","        # Hyperparameters of a model      \n","        self.num_nodes = num_nodes\n","        self.input_dim = input_dim\n","        self.num_classes = num_classes\n","        self.hid_dim = hid_dim    \n","        self.num_layers = num_layers\n","                \n","        self.indices = indices\n","        self.values = tf.cast(values, dtype='float32')\n","        \n","        # Define layers\n","        self.dense_layers = [Dense(self.hid_dim, kernel_initializer='he_normal', activation='relu') \n","                             for _ in range(self.num_layers)]\n","        self.dense_layers.append(Dense(self.num_classes, kernel_initializer='he_normal'))\n","        \n","    def call(self, x):\n","        A_size = (self.num_nodes, self.num_nodes)\n","        A = sparse.SparseTensor(\n","            self.indices, self.values, A_size)\n","        \n","        L = tf.cast(x, 'float32')\n","        for l in range(self.num_layers):\n","            L_new = sparse.sparse_dense_matmul(A, L)\n","            L = self.dense_layers[l](L_new)\n","        return self.dense_layers[-1](L)        \n","\n","    def loss_fn(self,logits, labels, indices):\n","        _labels = tf.gather_nd(labels, indices)\n","        _logits = tf.gather_nd(logits, indices)\n","        loss = tf.nn.softmax_cross_entropy_with_logits(labels=_labels, logits=_logits)\n","        return tf.reduce_mean(loss)\n","    \n","    def evaluate(self, x, labels, indices):\n","        logits = self.call(x)\n","        loss = self.loss_fn(logits, labels, indices)        \n","        _logits = tf.gather_nd(logits, indices)\n","        _labels = tf.gather_nd(labels, indices)\n"," \n","        pred = tf.argmax(_logits, axis=1)\n","        ans = tf.argmax(_labels, axis=1)\n","        correct = tf.equal(pred, ans)\n","        acc = tf.reduce_mean(tf.cast(correct, tf.float32))\n","        return loss, acc\n","    \n","    def train(self, x, labels, idx_train, idx_val, optimizer, max_epochs=20):\n","        for epoch in range(1, max_epochs+1):\n","            with tf.GradientTape() as tape:\n","                logits = self.call(x)\n","                train_loss = self.loss_fn(logits, labels, idx_train)\n","            \n","            grad_list = tape.gradient(train_loss, self.weights)\n","            grads_and_vars = zip(grad_list, self.weights)\n","            optimizer.apply_gradients(grads_and_vars)\n","            \n","            # Evaluation\n","            train_loss, train_acc = self.evaluate(x, labels, idx_train)\n","            valid_loss, valid_acc = self.evaluate(x, labels, idx_val)\n","            print(f\"Epoch {epoch:3d}: {train_loss:.4f}, {train_acc*100:.2f},\" \n","                  ,f\"{valid_loss:.4f}, {valid_acc*100:.2f}\")            "]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1659589542251,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"-hbL2duspiPU"},"outputs":[],"source":["def get_adj_matrix(ids):\n","    num_nodes = ids.shape[0]\n","    #cites = np.loadtxt('/content/drive/MyDrive/TA/NPEX4기/0804/cora/cora.cites', dtype=np.int32)\n","    cites = np.loadtxt('./cora/cora.cites', dtype=np.int32)\n","    id_map = {v: u for u, v in enumerate(ids)} # node id --> node index\n","    indices = [(e, e) for e in range(num_nodes)] # self loop\n","    for node1, node2 in cites:\n","        if node1 != node2:\n","            idx1 = id_map[node1]\n","            idx2 = id_map[node2]\n","            indices.append((idx1, idx2)) # Aij : node_i -> node_j\n","            indices.append((idx2, idx1))\n","    indices = np.array(indices)\n","    values = np.ones(indices.shape[0]) # number of edges\n","    return indices, values # not N x N but 3 * E"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1659589542252,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"j-XGvSDqpiPV"},"outputs":[],"source":["def normalize(indices, values, num_nodes, way='both'):\n","    values_sum = np.zeros(num_nodes)\n","    for node1, node2 in indices:\n","        values_sum[node1] += 1                \n","    if way == 'both': \n","        values /= np.sqrt(values_sum[indices[:, 1]])\n","        values /= np.sqrt(values_sum[indices[:, 0]])\n","    elif way == 'row': \n","        values /= values_sum[indices[:, 0]] \n","    elif way == 'col': \n","        values /= values_sum[indices[:, 1]]\n","    else:\n","        raise ValueError()\n","    return values     "]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3099,"status":"ok","timestamp":1659589545329,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"uCFrYwllpiPV","outputId":"2c1ffc4b-95d9-4111-cab1-d22794daf8bc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch   1: 1.7594, 66.07, 1.8604, 42.86\n","Epoch   2: 1.5264, 78.57, 1.7467, 50.00\n","Epoch   3: 1.2470, 78.57, 1.5820, 64.29\n","Epoch   4: 0.9777, 83.93, 1.4418, 64.29\n","Epoch   5: 0.7420, 85.71, 1.3196, 64.29\n","Epoch   6: 0.5482, 91.07, 1.2091, 64.29\n","Epoch   7: 0.3944, 94.64, 1.1128, 64.29\n","Epoch   8: 0.2761, 100.00, 1.0214, 64.29\n","Epoch   9: 0.1893, 100.00, 0.9471, 64.29\n","Epoch  10: 0.1262, 100.00, 0.8995, 64.29\n","Epoch  11: 0.0818, 100.00, 0.8770, 71.43\n","Epoch  12: 0.0522, 100.00, 0.8728, 71.43\n","Epoch  13: 0.0327, 100.00, 0.8780, 71.43\n","Epoch  14: 0.0200, 100.00, 0.8902, 71.43\n","Epoch  15: 0.0122, 100.00, 0.9102, 71.43\n","Epoch  16: 0.0074, 100.00, 0.9349, 71.43\n","Epoch  17: 0.0045, 100.00, 0.9635, 71.43\n","Epoch  18: 0.0027, 100.00, 0.9930, 71.43\n","Epoch  19: 0.0017, 100.00, 1.0225, 71.43\n","Epoch  20: 0.0011, 100.00, 1.0504, 71.43\n"]}],"source":["num_nodes = ids.shape[0]\n","indices, values = get_adj_matrix(ids)\n","values = normalize(indices, values, num_nodes, way='both') # Compare the result of row/ column/ both\n","\n","train_mask = np.expand_dims(idx_train, axis=1)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n","\n","gcn2 = GCN2(indices=indices, values=values,\n","           input_dim=x.shape[1], hid_dim=32, num_classes=num_classes, \n","            num_nodes=x.shape[0], num_layers=2)\n","_idx_train = np.expand_dims(idx_train, axis=1)\n","_idx_val = np.expand_dims(idx_valid, axis=1)\n","\n","gcn2.train(x=x, labels=y, idx_train=_idx_train, idx_val=_idx_val, optimizer=optimizer, max_epochs=20)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1659589545330,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"fXWAUlWGpiPV","outputId":"0bcb0473-a797-46a8-fc2a-b614c63d60aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(0.71, shape=(), dtype=float32)\n"]}],"source":["test_mask = np.expand_dims(idx_test, axis=1)\n","test_loss, test_acc = gcn2.evaluate(x=x, labels=y, indices=np.expand_dims(idx_test, axis=1))\n","print(test_acc)"]},{"cell_type":"markdown","metadata":{"id":"vQSAeFLZpiPW"},"source":["## Answers"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1659589545331,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"RpJJKlqYpiPW"},"outputs":[],"source":["# def call(self, x):\n","#     A_size = (self.num_nodes, self.num_nodes)\n","#     A = sparse.SparseTensor(\n","#         self.indices, self.values, A_size)\n","\n","#     L = tf.cast(x, 'float32')\n","#     for l in range(self.num_layers):\n","#         L_new = sparse.sparse_dense_matmul(A, L)\n","#         L_new = self.dense_layers[l](L_new)\n","#         if l>0:\n","#             L_new = L\n","#         L= L_new\n","#     return self.dense_layers[-1](L)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1659589545331,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"or6CxkavpiPW"},"outputs":[],"source":["# def get_adj_matrix(ids):\n","#     num_nodes = ids.shape[0]\n","#     cites = np.loadtxt('./cora/cora.cites', dtype=np.int32)\n","#     # {key: value} , dict[key] = value\n","#     id_map = {v: u for u, v in enumerate(ids)} # node id --> node index\n","#     indices = [(e, e) for e in range(num_nodes)] # self loop\n","#     for node1, node2 in cites:\n","#         if node1 != node2:\n","#             idx1 = id_map[node1]\n","#             idx2 = id_map[node2]\n","#             indices.append((idx1, idx2)) # Aij : node_i -> node_j\n","#             indices.append((idx2, idx1))\n","#     indices = np.array(indices)\n","#     values = np.ones(indices.shape[0]) # number of edges\n","#     return indices, values # not N x N but 3 * E"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1659589545331,"user":{"displayName":"Seungcheol Park","userId":"14338064939932031597"},"user_tz":-540},"id":"20-tKbIBpiPX"},"outputs":[],"source":["# def normalize(indices, values, num_nodes, way='both'):\n","#     values_sum = np.zeros(num_nodes)\n","#     for node1, node2 in indices:\n","#         values_sum[node1] += 1        \n","#     if way == 'both': \n","#         values /= np.sqrt(values_sum[indices[:, 1]])\n","#         values /= np.sqrt(values_sum[indices[:, 0]])\n","#     elif way == 'row': \n","#         values /= values_sum[indices[:, 0]] \n","#     elif way == 'col': \n","#         values /= values_sum[indices[:, 1]]\n","#     else:\n","#         raise ValueError()\n","#     return values     "]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"L7.2-lab-gcn-cora-2-TFv2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"bf789d3fe2e48003609d2b27099c8c5750f1d9c6ed54a4f20100144dcd5707b9"}}},"nbformat":4,"nbformat_minor":0}
