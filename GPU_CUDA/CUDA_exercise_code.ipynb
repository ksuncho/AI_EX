{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yAjbWOJ0bZZp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Aug 12 15:29:48 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 451.67       Driver Version: 451.67       CUDA Version: 11.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  GeForce RTX 207... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
            "| N/A   47C    P8    15W /  N/A |   1047MiB /  8192MiB |     10%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      1288    C+G   Insufficient Permissions        N/A      |\n",
            "|    0   N/A  N/A      1340    C+G   ...lPanel\\SystemSettings.exe    N/A      |\n",
            "|    0   N/A  N/A      4680    C+G   ...2txyewy\\TextInputHost.exe    N/A      |\n",
            "|    0   N/A  N/A      5808    C+G   ...8wekyb3d8bbwe\\Cortana.exe    N/A      |\n",
            "|    0   N/A  N/A      6920    C+G   ...kyb3d8bbwe\\Calculator.exe    N/A      |\n",
            "|    0   N/A  N/A      7412    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
            "|    0   N/A  N/A      7656    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
            "|    0   N/A  N/A      9228    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A      9620    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
            "|    0   N/A  N/A     10032    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
            "|    0   N/A  N/A     10832    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
            "|    0   N/A  N/A     11640    C+G   ...icrosoft VS Code\\Code.exe    N/A      |\n",
            "|    0   N/A  N/A     12168    C+G   ...ge\\Application\\msedge.exe    N/A      |\n",
            "|    0   N/A  N/A     13672    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
            "|    0   N/A  N/A     17308    C+G   ...wekyb3d8bbwe\\Video.UI.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pcOkv9VYyhp4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvcc'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V_1NVhJmbKyx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to c:\\users\\ai_15\\appdata\\local\\temp\\pip-req-build-4pi06zxc\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit aac710a35f52bb78ab34d2e52517237941399eff\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py): started\n",
            "  Building wheel for NVCCPlugin (setup.py): finished with status 'done'\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-py3-none-any.whl size=4320 sha256=b2eeecc5585478f91ebe900ec65e909740e1f6cdb06e46a3f97e0b79babcdc80\n",
            "  Stored in directory: C:\\Users\\AI_15\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-i_r7x6x6\\wheels\\f3\\08\\cc\\e2b5b0e1c92df07dbb50a6f024a68ce090f5e7b2316b41756d\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "\n",
            "[notice] A new release of pip available: 22.1.2 -> 22.2.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git 'C:\\Users\\AI_15\\AppData\\Local\\Temp\\pip-req-build-4pi06zxc'\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RsQJgSTqy7ss"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "directory c:\\Users\\AI_15\\momo\\python_prj\\2022_AI_Expert\\GPU_CUDA\\src already exists\n",
            "Out bin c:\\Users\\AI_15\\momo\\python_prj\\2022_AI_Expert\\GPU_CUDA\\result.out\n"
          ]
        }
      ],
      "source": [
        "%load_ext nvcc_plugin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tVJCq52t1ov1"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] 지정된 파일을 찾을 수 없습니다",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\AI_15\\momo\\python_prj\\2022_AI_Expert\\GPU_CUDA\\CUDA_exercise_code.ipynb 셀 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/AI_15/momo/python_prj/2022_AI_Expert/GPU_CUDA/CUDA_exercise_code.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mcu\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m#include <iostream>\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    int\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    main()\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m{\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    std::cout << \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWelcome To GeeksforGeeks\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m;\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    return 0;\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m}\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\AI_15\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2358\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2356\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m   2357\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[1;32m-> 2358\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   2359\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
            "File \u001b[1;32mc:\\Users\\AI_15\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\v1\\v1.py:52\u001b[0m, in \u001b[0;36mNVCCPlugin.cu\u001b[1;34m(self, line, cell)\u001b[0m\n\u001b[0;32m     50\u001b[0m     f\u001b[39m.\u001b[39mwrite(cell)\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile(file_path)\n\u001b[0;32m     53\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun(file_path, timeit\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mtimeit)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m subprocess\u001b[39m.\u001b[39mCalledProcessError \u001b[39mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\AI_15\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\v1\\v1.py:23\u001b[0m, in \u001b[0;36mNVCCPlugin.compile\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompile\u001b[39m(file_path):\n\u001b[1;32m---> 23\u001b[0m     subprocess\u001b[39m.\u001b[39;49mcheck_output(\n\u001b[0;32m     24\u001b[0m         [compiler, file_path \u001b[39m+\u001b[39;49m ext, \u001b[39m\"\u001b[39;49m\u001b[39m-o\u001b[39;49m\u001b[39m\"\u001b[39;49m, file_path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39m.out\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m-Wno-deprecated-gpu-targets\u001b[39;49m\u001b[39m'\u001b[39;49m], stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mSTDOUT)\n",
            "File \u001b[1;32mc:\\Users\\AI_15\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py:415\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    412\u001b[0m         empty \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    413\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[1;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    416\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
            "File \u001b[1;32mc:\\Users\\AI_15\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py:493\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    491\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 493\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39;49mpopenargs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    494\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    495\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
            "File \u001b[1;32mc:\\Users\\AI_15\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py:858\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    854\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    855\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    856\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 858\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    859\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    860\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    861\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    862\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    863\u001b[0m                         errread, errwrite,\n\u001b[0;32m    864\u001b[0m                         restore_signals, start_new_session)\n\u001b[0;32m    865\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    867\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
            "File \u001b[1;32mc:\\Users\\AI_15\\AppData\\Local\\Programs\\Python\\Python38\\lib\\subprocess.py:1311\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1309\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1311\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1312\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1313\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1314\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1315\u001b[0m                              creationflags,\n\u001b[0;32m   1316\u001b[0m                              env,\n\u001b[0;32m   1317\u001b[0m                              cwd,\n\u001b[0;32m   1318\u001b[0m                              startupinfo)\n\u001b[0;32m   1319\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1320\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1325\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1327\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1328\u001b[0m                          errread, errwrite)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] 지정된 파일을 찾을 수 없습니다"
          ]
        }
      ],
      "source": [
        "%%cu\n",
        "#include <iostream>\n",
        "    int\n",
        "    main()\n",
        "{\n",
        "    std::cout << \"Welcome To GeeksforGeeks\\n\";\n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7g7PnHjB585"
      },
      "outputs": [],
      "source": [
        "%%cu\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "/*************************************************\n",
        "Function name: gpu_matrix_mult\n",
        "\n",
        "Parameters:\n",
        "            &a GPU device pointer to a m X n matrix (A)\n",
        "            &b GPU device pointer to a n X k matrix (B)\n",
        "            &c GPU device output pointer to a m X k matrix (C)\n",
        "\n",
        "Note:\n",
        "      grid and block should be configured as:\n",
        "            dim3 dimGrid((k + BLOCKSIZE - 1) / BLOCK_SIZE, (m + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "            dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "*************************************************/\n",
        "\n",
        "__global__ void gpu_matrix_mult(int *a, int *b, int *c, int m, int n, int k)\n",
        "{\n",
        "    /*\n",
        "    Part 1. Write GPU kernel code here for executing matrix multiplication\n",
        "    Hint: Column index is calculated as, blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    \n",
        "    Part 1 ends here\n",
        "    */\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int sum;\n",
        " \n",
        "    if(col < k && row < m)\n",
        "    {\n",
        "        sum=0;\n",
        "        for(int i=0; i < n; i++)\n",
        "        {\n",
        "            sum += a[row*n + i] * b[i * k + col];\n",
        "        }\n",
        "        c[row*k + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "/*************************************************\n",
        "Function name: gpu_tiled_matrix_mult\n",
        "\n",
        "Parameters:\n",
        "            &a GPU device pointer to a n X n matrix (A)\n",
        "            &b GPU device pointer to a n X n matrix (B)\n",
        "            &c GPU device output pointer to a n X n matrix (C)\n",
        "\n",
        "Note:\n",
        "      grid and block should be configured as:\n",
        "            dim3 dimGrid((k + BLOCKSIZE - 1) / BLOCK_SIZE, (m + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "            dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "*************************************************/\n",
        "\n",
        "__global__ void gpu_tiled_matrix_mult(int *d_a, int *d_b, int *d_result, int n)\n",
        "{\n",
        "    /*\n",
        "    Part 2. Write GPU kernel code for executing tiled matrix multiplication\n",
        "    Hint: Need __syncthreads() for the correct results\n",
        "\n",
        "\n",
        "    Part 2 ends here\n",
        "    */\n",
        "    int k = 32;\n",
        "    \n",
        "    int tile_A = blockIdx.y * blockDim.y;\n",
        "    int tile_B = blockIdx.x * blockDim.x;\n",
        " \n",
        "    int row = tile_A + threadIdx.y;\n",
        "    int col = tile_B + threadIdx.x;\n",
        " \n",
        "    __shared__ int aTile[32][32];\n",
        "    __shared__ int bTile[32][32];\n",
        "    aTile[threadIdx.y][threadIdx.x] = d_a[row * k + threadIdx.x];\n",
        "    bTile[threadIdx.y][threadIdx.x] = d_b[threadIdx.y * n + col];\n",
        "    __syncthreads();\n",
        " \n",
        "    int tile_element_sum = 0;\n",
        "    \n",
        "    for (int i = 0; i < k; i++) {\n",
        "        tile_element_sum += aTile[threadIdx.y][i] * bTile[i][threadIdx.x];\n",
        "    }\n",
        "\n",
        "    d_result[row * n + col] = tile_element_sum;\n",
        "}\n",
        "\n",
        "/*************************************************\n",
        "Function name: cpu_matrix_mult\n",
        "\n",
        "Parameters:\n",
        "            &a CPU host pointer to a n X n matrix (A)\n",
        "            &b CPU host pointer to a n X n matrix (B)\n",
        "            &c CPU host output pointer to a n X n matrix (C)\n",
        "*************************************************/\n",
        "\n",
        "__host__ void cpu_matrix_mult(int *h_a, int *h_b, int *h_result, int m, int n, int k) {\n",
        "    for (int i = 0; i < m; ++i)\n",
        "    {\n",
        "        for (int j = 0; j < k; ++j)\n",
        "        {\n",
        "            int tmp = 0.0;\n",
        "            for (int h = 0; h < n; ++h)\n",
        "            {\n",
        "                tmp += h_a[i * n + h] * h_b[h * k + j];\n",
        "            }\n",
        "            h_result[i * k + j] = tmp;\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "/*************************************************\n",
        "Function name: main\n",
        "\n",
        "Test and Compare\n",
        "*************************************************/\n",
        "\n",
        "int main(int argc, char const *argv[])\n",
        "{\n",
        "    int m, n, k;\n",
        "    srand(time(0));\n",
        "    \n",
        "    //Set the size of matrices\n",
        "    m = 256;\n",
        "    n = 256;\n",
        "    k = 256;\n",
        "\n",
        "    /*\n",
        "    Part 3-1. Allocate memory in host DRAM, h_cc is used to store the CPU result\n",
        "\n",
        "    int *h_a, *h_b, *h_c, *h_cc;\n",
        "    \n",
        "\n",
        "    Part 3-1 ends here\n",
        "    */\n",
        "    int *h_a, *h_b, *h_c, *h_cc;\n",
        "    \n",
        "    cudaMallocHost((void **) &h_a, sizeof(int) * m * n);\n",
        "    cudaMallocHost((void **) &h_b, sizeof(int) * n * k);\n",
        "    cudaMallocHost((void **) &h_c, sizeof(int) * m * k);\n",
        "    cudaMallocHost((void **) &h_cc, sizeof(int) * m * k);\n",
        " \n",
        "    int i, j;\n",
        "    // Random initialize matrix A\n",
        "    for (int i = 0; i < m; ++i) {\n",
        "        for (int j = 0; j < n; ++j) {\n",
        "            h_a[i * n + j] = rand() % 1024;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Random initialize matrix B\n",
        "    for (int i = 0; i < n; ++i) {\n",
        "        for (int j = 0; j < k; ++j) {\n",
        "            h_b[i * k + j] = rand() % 1024;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    float gpu_elapsed_time_ms, cpu_elapsed_time_ms;\n",
        "\n",
        "    // Events to measure the execution time\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Start to measure the execution time of GPU version\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    /*\n",
        "    Part 3-2. Allocate memory space on the device (GPU)\n",
        "              & Copy matrix A and B from host to device memory\n",
        "    \n",
        "    int *d_a, *d_b, *d_c;\n",
        "\n",
        "\n",
        "    Part 3-2 ends here\n",
        "    */\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    \n",
        "    cudaMalloc((void **) &d_a, sizeof(int) * m * n);\n",
        "    cudaMalloc((void **) &d_b, sizeof(int) * n * k);\n",
        "    cudaMalloc((void **) &d_c, sizeof(int) * m * k);\n",
        " \n",
        "    cudaMemcpy(d_a, h_a, sizeof(int) * m * n, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, h_b, sizeof(int) * n * k, cudaMemcpyHostToDevice);\n",
        " \n",
        "    unsigned int grid_rows = (m + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    unsigned int grid_cols = (k + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
        "    dim3 dimGrid(grid_cols, grid_rows);\n",
        "    dim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "    /*\n",
        "    Part 3-3. Launch GPU kernel\n",
        "              & Transfer results from the device to host\n",
        "    Note:\n",
        "          For the tiled multiplication with square matrices (i.e., m = n = k), launch gpu_square_matrix_mult\n",
        "          Otherwise, launch regular matrix multiplication kernel\n",
        "    \n",
        "    if (m == n && n == k && n > BLOCK_SIZE && (n % BLOCK_SIZE == 0)) {\n",
        "        Launch the tiled matrix multiplication kernel\n",
        "    }\n",
        "    else {\n",
        "        Launch the normal matrix multplication kernel\n",
        "    }\n",
        "    \n",
        "    // Transfer the results from device to host\n",
        "    \n",
        "    Part 3-3 ends here\n",
        "    */\n",
        "    gpu_matrix_mult<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, m, n, k);\n",
        "    //gpu_tiled_matrix_mult<<<dimGrid, dimBlock>>>(d_a, d_b, d_c, m, n, k);\n",
        "    cudaMemcpy(h_c, d_c, sizeof(int) * m * k, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cudaDeviceSynchronize();\n",
        "    \n",
        "    // Time counting terminate\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    // GPU computing time elapse\n",
        "    cudaEventElapsedTime(&gpu_elapsed_time_ms, start, stop);\n",
        "    printf(\"\\n\\nGPU execution time on matrix multiplication of %dx%d . %dx%d: %f ms.\\n\\n\", m, n, n, k, gpu_elapsed_time_ms);\n",
        "\n",
        "    // CPU version\n",
        "    cudaEventRecord(start, 0);\n",
        "\n",
        "    cpu_matrix_mult(h_a, h_b, h_cc, m, n, k);\n",
        "\n",
        "    cudaEventRecord(stop, 0);\n",
        "    cudaEventSynchronize(stop);\n",
        "    cudaEventElapsedTime(&cpu_elapsed_time_ms, start, stop);\n",
        "    printf(\"CPU execution time on matrix multiplication of %dx%d . %dx%d: %f ms.\\n\\n\", m, n, n, k, cpu_elapsed_time_ms);\n",
        "\n",
        "    // Validate the results computed by GPU\n",
        "    int all_ok = 1;\n",
        "    for (int i = 0; i < m; ++i) {\n",
        "        for (int j = 0; j < k; ++j) {\n",
        "            // Uncomment below to see the actual results on both CPU and GPU\n",
        "            // printf(\"CPU result [%d][%d]:%d == GPU result [%d][%d]:%d, \", i, j, h_cc[i * k + j], i, j, h_c[i * k + j]);\n",
        "            if (h_cc[i * k + j] != h_c[i * k + j]) {\n",
        "                all_ok = 0;\n",
        "            }\n",
        "        }\n",
        "        // printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Compute the speedup\n",
        "    if (all_ok) {\n",
        "        printf(\"All results are correct !!!, speedup = %f\\n\", cpu_elapsed_time_ms / gpu_elapsed_time_ms);\n",
        "    }\n",
        "    else {\n",
        "        printf(\"Incorrect results\\n\");\n",
        "    }\n",
        "\n",
        "    /*\n",
        "    Part 3-4. Free the device and host memory\n",
        "\n",
        "\n",
        "    Part 3-4 ends here\n",
        "    */\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_c);\n",
        "    cudaFreeHost(h_a);\n",
        "    cudaFreeHost(h_a);\n",
        "    cudaFreeHost(h_c);\n",
        "    cudaFreeHost(h_cc);\n",
        " \n",
        "    return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4803E113Ak1"
      },
      "outputs": [],
      "source": [
        "%%cu\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <cstdlib>\n",
        "#include <time.h>\n",
        "#include <iostream>\n",
        "#include <string>\n",
        "#include <math.h>\n",
        "#include <assert.h>\n",
        "\n",
        "#define BLOCK_SIZE 16\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "\n",
        "__global__ void Convolution(float* A, float* B, float* C, int numARows, int numACols, int numBRows, int numBCols, int numCRows, int numCCols)\n",
        "{\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int col = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    float sum;\n",
        "   \n",
        "    //A * B = C\n",
        "    if(row<numCRows&&col<numCCols){\n",
        "        sum =0;\n",
        "\n",
        "\t\t/*Part 1. write GPU kernel code for executing convolution\n",
        "\t\t**convolution with the entire filter becomes the one element of the matrix C\n",
        "\t\t***row/col indicates the index of output matrix C\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\t\tPart 1 ends\n",
        "\t\t*/\n",
        "\t\tfor(size_t i=0; i<numBCols; i++){\n",
        "\t\t\tfor(size_t j=0; j<numBRows; j++){\n",
        "\t\t\t\t  sum += A[row*numACols+i*numACols+col+j]*B[i*numBCols+j];\n",
        "\t\t\t}\t  \n",
        "\t\t}\n",
        "\t\tC[row*numCCols+col]=sum;\t\n",
        "    \n",
        "    }    \n",
        "\n",
        "}\n",
        "\n",
        "__host__ void cpu_Convolution(float *A, float *B, float *C, int asize, int bsize){\n",
        "\n",
        "\tint csize=asize-bsize+1;\n",
        "\tint sum;\n",
        "\tfor(int i=0;i<csize;i++){\n",
        "\t\t\n",
        "\t\tfor (int j=0;j<csize;j++){\n",
        "\t\t\tsum=0;\n",
        "\t\t\tfor(int k=0;k<bsize;k++){\n",
        "\t\t\t\t\n",
        "\t\t\t\tfor(int l=0;l<bsize;l++){\n",
        "\t\t\t\t\tsum+=A[i*asize+k*asize+j+l]*B[k*bsize+l];\n",
        "\n",
        "\t\t\t\t}\n",
        "\t\t\t\t\n",
        "\t\t\t}\n",
        "\t\t\tC[i*csize+j]=sum;\n",
        "\t\t}\n",
        "\n",
        "\n",
        "\n",
        "\t}\n",
        "\t\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "}\n",
        "\n",
        "void randomInit(float* data, int size)\n",
        "{\n",
        "\tfor (int i = 0; i < size; ++i)\n",
        "\t\tdata[i] = rand() %10;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\tsrand(time(0));\n",
        "\tint a, b, c;\n",
        "\tcudaEvent_t start_G, stop_G;\n",
        "\tfloat gpu_miliseconds, cpu_miliseconds;\n",
        "\tcudaEventCreate(&start_G);\n",
        "\tcudaEventCreate(&stop_G);\n",
        "\ta=5; \t//size of the feature map \n",
        "\tb=3;\t//size of the filter\n",
        "    c=a-b+1;\n",
        "\n",
        "\t/*Part 2-1.\tinitilize matrix and filter\n",
        "\twhen the input and filter size are a and b, what is the output size c?\n",
        "\tc= ??; \n",
        "\n",
        "\tPart 2-1 ends\n",
        "\t*/ \n",
        "\tunsigned int size_A = a * a;\n",
        "\tunsigned int size_B = b * b;\n",
        "\tunsigned int size_C = c * c;\n",
        "\t\n",
        "\t/*Part 2-2. initialize matrix and filter\n",
        "\tallocate memory in host DRAM\n",
        "\tfloat *h_A, *h_B, *h_C, *h_C_cpu;\n",
        "\n",
        "\t*/\n",
        "\tunsigned int mem_size_A = sizeof(float) * size_A;\n",
        "\tfloat* h_A = (float*)malloc(mem_size_A);\n",
        "\tunsigned int mem_size_B = sizeof(float) * size_B;\n",
        "\tfloat* h_B = (float*)malloc(mem_size_B);\n",
        "\tunsigned int mem_size_C = sizeof(float) * size_C;\n",
        "\tfloat* h_C = (float*)malloc(mem_size_C);\n",
        "\tfloat* h_C_cpu = (float*)malloc(mem_size_C);\n",
        "\n",
        "\trandomInit(h_A, size_A);\n",
        "\n",
        "\tfor (int i = 0; i < size_B; ++i)\n",
        "    {\n",
        "        h_B[i] = rand() %4;\n",
        "    }\n",
        "\n",
        "\t/*Part 3. allocate device memory and memory copy from the host\n",
        "\tallocate memory space on GPU, then copy matrix A and B from the host to GPU\n",
        "\tfloat *d_A, *d_B, *d_C;\t\t//h_A, h_B -> d_A, d_B\n",
        "\n",
        "\tPart 3 ends\n",
        "\t*/\n",
        "\tfloat *d_A, *d_B, *d_C;\t\t//h_A, h_B -> d_A, d_B\n",
        "\n",
        "\tcudaMalloc((void**)&d_A, mem_size_A);\n",
        "\tcudaMalloc((void**)&d_B, mem_size_B);\n",
        "\tcudaMalloc((void**)&d_C, mem_size_C);\n",
        "\n",
        "\tcudaMemcpy(d_A, h_A, mem_size_A, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(d_B, h_B, mem_size_B, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tunsigned int grid_rows= (c+BLOCK_SIZE-1) / BLOCK_SIZE;\n",
        "\tunsigned int grid_cols= (c+BLOCK_SIZE-1) / BLOCK_SIZE;\n",
        "\t\n",
        "\tdim3 dimGrid(grid_cols,grid_rows);\t\n",
        "\tdim3 dimBlock(BLOCK_SIZE,BLOCK_SIZE);\n",
        "\t\n",
        "\tcudaEventRecord(start_G,0);\n",
        "\n",
        "\t/*Part 4-1. launch GPU kerenl\n",
        "\tlaunch GPU kernel and execute convolution between A and B, providing values for C\n",
        "\t\n",
        "\t\n",
        "\n",
        "\tPart 4-1 ends\n",
        "\t*/\n",
        "\n",
        "\tConvolution<<<dimGrid, dimBlock>>>(d_A, d_B, d_C, a, a, b, b, c, c);\n",
        "\n",
        "\tcudaEventRecord(stop_G,0);\n",
        "\n",
        "\tcudaEventSynchronize(stop_G);\n",
        "\t/*Part 4-2. data copy from device to host\n",
        "\ttransfer the calculated data from gpu to host ( d_C -> h_C)\n",
        "\n",
        "\t*/\n",
        "\tcudaEventRecord(stop_G,0);\n",
        " \n",
        "\tcudaEventSynchronize(stop_G);\n",
        "\n",
        "\tcudaMemcpy(h_C, d_C, mem_size_C, cudaMemcpyDeviceToHost);\n",
        "\n",
        "\tcudaEventElapsedTime(&gpu_miliseconds, start_G, stop_G);\n",
        "\n",
        "\tprintf(\"\\nTime took to compute matrix A(%d x %d) with filter B(%d x %d) on GPU is %f ms  \\n \\n\", a, a,b,b, gpu_miliseconds);\n",
        "    printf(\"matrix A\\n\");\n",
        "\tfor (int i = 0;i < a;i++)\n",
        "\t{\n",
        "\t\tfor (int j = 0;j < a;j++)\n",
        "\t\t{\n",
        "\t\t\tprintf(\"%f\\t\", h_A[i*a + j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}printf(\"\\n\");\n",
        "    printf(\"matrix B\\n\");\n",
        "    for (int i = 0;i < b;i++)\n",
        "\t{\n",
        "\t\tfor (int j = 0;j < b;j++)\n",
        "\t\t{\n",
        "\t\t\tprintf(\"%f\\t\", h_B[i*b + j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}printf(\"\\n\");\n",
        "    printf(\"matrix C\\n\");\n",
        "\tfor (int i = 0;i < c;i++)\n",
        "\t{\n",
        "\t\tfor (int j = 0;j < c;j++)\n",
        "\t\t{\n",
        "\t\t\tprintf(\"%f\\t\", h_C[i*c + j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\tcudaEventRecord(start_G, 0);\n",
        "\tcpu_Convolution(h_A, h_B, h_C_cpu, a,b);\t// convolution execution with CPU\n",
        "\tcudaEventRecord(stop_G,0);\n",
        "\tcudaEventSynchronize(stop_G);\n",
        "\tcudaEventElapsedTime(&cpu_miliseconds, start_G, stop_G);\n",
        "\tprintf(\"\\nTime took to compute matrix A(%d x %d) with filter B(%d x %x) on CPU is %f ms  \\n \\n\", a, a,b,b, cpu_miliseconds);\n",
        "    \n",
        "\tfor (int i = 0;i < c;i++)\n",
        "\t{\n",
        "\t\tfor (int j = 0;j < c;j++)\n",
        "\t\t{\n",
        "\t\t\tprintf(\"%f\\t\", h_C_cpu[i*c + j]);\n",
        "\t\t}\n",
        "\t\tprintf(\"\\n\");\n",
        "\t}\n",
        "\n",
        "\tfree(h_A);\n",
        "\tfree(h_B);\n",
        "\tfree(h_C);\n",
        "\tfree(h_C_cpu);\n",
        "\tcudaFree(d_A);\n",
        "\tcudaFree(d_B);\n",
        "\tcudaFree(d_C);\n",
        "\n",
        "\treturn EXIT_SUCCESS;\n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CUDA_exercise_code.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "bf789d3fe2e48003609d2b27099c8c5750f1d9c6ed54a4f20100144dcd5707b9"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
