{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Samsung-KoBERT-KorQuAD.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ewZ528jXX2M3"},"source":["# 1. Install and import packages\n","\n","* 본 실습에 필요한 패키지를 설치합니다.\n","* KorQuAD 에 사전학습된 모델을 사용하기 위하여 KoBERT-KorQuAD 를 설치합니다."]},{"cell_type":"code","metadata":{"id":"iOAu3ary51NA"},"source":["!git clone https://github.com/monologg/KoBERT-KorQuAD kobert\n","!pip install transformers==2.9.1\n","!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AXQVFwGMvtDe"},"source":["import os, json\n","import numpy as np\n","from tqdm.notebook import tqdm\n","\n","import argparse\n","import glob\n","import logging\n","import os\n","import random\n","import timeit\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","from transformers.data.metrics.squad_metrics import (\n","    compute_predictions_log_probs,\n","    compute_predictions_logits,\n","    squad_evaluate,\n",")\n","from transformers.data.processors.squad import SquadResult, SquadV1Processor, SquadV2Processor\n","from transformers import (\n","    WEIGHTS_NAME,\n","    AdamW,\n","    BertConfig,\n","    BertForQuestionAnswering,\n","    BertTokenizer,\n","    get_linear_schedule_with_warmup,\n","    squad_convert_examples_to_features\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTZpDXotSwL8"},"source":["# 2. Explore Data"]},{"cell_type":"markdown","metadata":{"id":"Evu-cSa9S0fk"},"source":["## 2.1. Raw data 확인"]},{"cell_type":"code","metadata":{"id":"AWGIqXtQtRWe"},"source":["train_data = json.load(open('./kobert/data/KorQuAD_v1.0_train.json', 'r'))\n","dev_data = json.load(open('./kobert/data/KorQuAD_v1.0_dev.json', 'r'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gK0fBuhdS4Lu"},"source":["train_data[\"data\"] = train_data[\"data\"][:150]\n","with open('./kobert/data/KorQuAD_v1.0_train.json', 'w') as fout:\n","  json.dump(train_data, fout, indent=2)\n","\n","dev_data[\"data\"] = dev_data[\"data\"][:50]\n","with open('./kobert/data/KorQuAD_v1.0_dev.json', 'w') as fout:\n","  json.dump(dev_data, fout, indent=2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CAghhMEZtTvr"},"source":["# train_data[\"data\"]\n","print(\"Nb of data: \", len(train_data[\"data\"]))\n","print()\n","# print(train_data[\"data\"][0].keys())\n","# print(len(train_data[\"data\"][0][\"paragraphs\"]))\n","print(\"QA example: \")\n","for k, v in train_data[\"data\"][0][\"paragraphs\"][0][\"qas\"][0].items():\n","    print(k, v)\n","print()\n","print(\"Context example: \")\n","train_data[\"data\"][0][\"paragraphs\"][0][\"context\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K6s_AGGYxlHS"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rAq_XeeyThg0"},"source":["## 2.2. 모델에 입력될 데이터로 변환\n","\n","* 한 데이터당 context, qa pair 가 tokenizer 로 처리되어 모델에 입력되도록 전처리를 해야합니다.\n","* 전처리를 위하여 transformers 라이브러리에서 제공하는 함수를 사용합니다.\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"FtBRW4byxvGh"},"source":["from transformers.data.processors.squad import SquadProcessor, SquadV1Processor\n","from transformers.data.processors.squad import squad_convert_examples_to_features"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O_GxOLfcxvxT"},"source":["processor = SquadV1Processor()\n","train_examples = processor.get_train_examples('./kobert/data', 'KorQuAD_v1.0_train.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kbEdLJkqyuL6"},"source":["from transformers import BertModel, BertConfig, AdamW\n","from kobert.tokenization_kobert import KoBertTokenizer\n","\n","tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kR1GaA0Xy2KX"},"source":["features, train_dataset = squad_convert_examples_to_features(\n","            examples=train_examples,\n","            tokenizer=tokenizer, # Tokenizer 설정\n","            max_seq_length=512,\n","            doc_stride=128, \n","            max_query_length=64,\n","            is_training=False,\n","            return_dataset=\"pt\", \n","            tqdm_enabled=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i9hs6dKcy6Ec"},"source":["len(train_dataset[200])\n","print(train_dataset[200])\n","# all_input_ids,\n","# all_attention_masks,\n","# all_token_type_ids,\n","# all_start_positions,\n","# all_end_positions,\n","# all_cls_index,\n","# all_p_mask,\n","# all_is_impossible,"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fV2qFB1c0pm5"},"source":["\" \".join(tokenizer.convert_ids_to_tokens(train_dataset[200][0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15cvjMMG02WC"},"source":["print(train_dataset[200][3], train_dataset[200][4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QW2k31i6CZ_I"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIuy736O-ECn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tA4P1WjmT0xJ"},"source":["# 3. Load model\n","* 모델은 사전학습된 KoBERT-KorQuAD 를 사용합니다.\n","* 모델의 from_pretrained 인자에 들어갈 model shortcut 에 따라 가져오는 pretrained model 이 달라집니다."]},{"cell_type":"markdown","metadata":{"id":"uqv1lnSOaBmv"},"source":[""]},{"cell_type":"code","metadata":{"id":"broL_ntXm6NC"},"source":["tokenizer.tokenize(\"가장 위대한 기념물을 짓기로 결정했습니다\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-jqaTbN-L24"},"source":["####################### TODO ###############################\n","# model, tokenizer, config 를 선언하세요. \n","# model shortcut: monologg/kobert\n","# BertForQuestionAnswering, KoBertTokenizer, BertConfig\n","##############################################################\n","model = BertForQuestionAnswering.from_pretrained('monologg/kobert')\n","tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n","config = BertConfig.from_pretrained('monologg/kobert')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LtUYp9ei-OAL"},"source":["# model 을 cuda 에 올리기\n","device = torch.device(\"cuda\" )\n","model.to(device) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N_bCLpMtxB3v"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcuWICo5m3XE"},"source":["\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8JsHqc5cl-V1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rv_qhzEban8o"},"source":["# 4. Train the model "]},{"cell_type":"markdown","metadata":{"id":"4gM_RN1rxmv2"},"source":["## 4.1. Training parameter setup"]},{"cell_type":"code","metadata":{"id":"vVAgiLUlBMV6"},"source":["# training 을 위한 파라미터 설정\n","params = {\n"," 'max_seq_length': 512,\n"," 'doc_stride': 128,\n"," 'max_query_length': 64,\n"," 'do_lower_case': False,\n","\n"," 'num_train_epochs': 2,\n"," 'per_gpu_train_batch_size': 8,\n"," 'per_gpu_eval_batch_size': 8,\n","\n"," 'learning_rate': 5e-05,\n"," 'gradient_accumulation_steps': 2,\n"," 'weight_decay': 0.0,\n"," 'adam_epsilon': 1e-08,\n"," 'max_grad_norm': 1.0,\n"," 'warmup_steps': 0,\n","\n"," 'save_steps': 200,\n"," 'output_dir': 'models',\n"," 'max_answer_length': 30,\n"," 'n_best_size': 20,\n"," 'threads': 1 \n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1SWORe2iBdxU"},"source":["from argparse import Namespace\n","args = argparse.Namespace()\n","args = vars(args)\n","\n","args.update(params)\n","args = Namespace(**args)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CRF7Icdmxxqo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGT7nggKWABi"},"source":["## 4.2. 데이터 준비"]},{"cell_type":"code","metadata":{"id":"G51YIw7nVPP0"},"source":["train_batch_size = args.per_gpu_train_batch_size\n","train_sampler = RandomSampler(train_dataset) \n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=train_batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qxo8eqGUWNa5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Nx6VtDk4WJzQ"},"source":["## 4.3. Start training!"]},{"cell_type":"code","metadata":{"id":"cNostQQRPMEL"},"source":["# Optimizer 설정\n","optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gy8P8YjS_CZl"},"source":["# Scheduler 사용할 경우\n","# optimizer = AdamW(model.parameters(), lr=args.learning_rate, eps=args.adam_epsilon)\n","# t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n","# scheduler = get_linear_schedule_with_warmup(\n","#     optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uC5gBcO-mwYy"},"source":["global_step = 1\n","\n","tr_loss, logging_loss = 0.0, 0.0\n","model.zero_grad()\n","model.train()\n","for _ in range(args.num_train_epochs):\n","    epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\", position=0)\n","    for step, batch in enumerate(epoch_iterator):      \n","        batch = tuple(t.to(device) for t in batch)\n","\n","        inputs = {\n","            \"input_ids\": batch[0],\n","            \"attention_mask\": batch[1],\n","            \"token_type_ids\": batch[2],\n","            \"start_positions\": batch[3],\n","            \"end_positions\": batch[4],\n","        }\n","\n","        outputs = model(**inputs)\n","        loss = outputs[0]\n","        loss = loss / args.gradient_accumulation_steps\n","        loss.backward()\n","\n","        tr_loss += loss.item()\n","        global_step += 1\n","\n","        if (step+1) % args.gradient_accumulation_steps == 0:\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n","            optimizer.step()\n","            # scheduler.step() \n","            model.zero_grad()\n","            \n","        if args.save_steps > 0 and global_step % args.save_steps == 0:\n","            print('Global Step: {} | Train Loss: {:.3f} '.format(global_step, (tr_loss-logging_loss)/args.save_steps))\n","\n","            logging_loss = tr_loss\n","\n","            if not os.path.exists(args.output_dir):\n","                os.makedirs(args.output_dir)\n","            torch.save(model.state_dict(), os.path.join(args.output_dir, \"checkpoint{}.pth\".format(global_step)))\n","            tokenizer.save_pretrained(args.output_dir)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VNHjaIRhtsO3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Cx4HMYqtsM5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DH5D079Cx477"},"source":["# 5. Evaluate"]},{"cell_type":"markdown","metadata":{"id":"l8Po-9Z6x8kj"},"source":["## 5.1. Load eval dataset"]},{"cell_type":"code","metadata":{"id":"5LP93s0qyAn1"},"source":["eval_examples = processor.get_dev_examples('./kobert/data', 'KorQuAD_v1.0_dev.json')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_v2gvWCStsH1"},"source":["eval_features, eval_dataset = squad_convert_examples_to_features(\n","            examples=eval_examples,\n","            tokenizer=tokenizer,\n","            max_seq_length=args.max_seq_length,\n","            doc_stride=args.doc_stride,\n","            max_query_length=args.max_query_length,\n","            is_training=False,\n","            return_dataset=\"pt\",\n","            tqdm_enabled=False,\n","            threads=args.threads,\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-wmCIKIxudNR"},"source":["args.eval_batch_size = args.per_gpu_eval_batch_size\n","eval_sampler = SequentialSampler(eval_dataset)\n","eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, \n","                             batch_size=args.eval_batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SpaH0J-1yLSI"},"source":["## 5.2. Evaluate"]},{"cell_type":"code","metadata":{"id":"BvB6bHXIunsA"},"source":["all_results = []\n","\n","for batch in tqdm(eval_dataloader, desc=\"Evaluating\", position=0, leave=True):\n","    model.eval()\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    with torch.no_grad():\n","        inputs = {\n","            \"input_ids\": batch[0],\n","            \"attention_mask\": batch[1],\n","            \"token_type_ids\": batch[2],\n","        }\n","\n","        example_indices = batch[3]\n","\n","        outputs = model(**inputs)\n","           \n","    for i, example_index in enumerate(example_indices):\n","        eval_feature = eval_features[example_index.item()]\n","        unique_id = int(eval_feature.unique_id)\n","\n","        output = [(output[i]).detach().cpu().tolist() for output in outputs]\n","        \n","        start_logits, end_logits = output\n","        \n","        result = SquadResult(unique_id, start_logits, end_logits)\n","\n","        all_results.append(result)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xzb5IlfdvhxY"},"source":["output_prediction_file = os.path.join(args.output_dir, \"predictions.json\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eTC26pE8vSoE"},"source":["predictions = compute_predictions_logits(\n","    eval_examples,\n","    eval_features,\n","    all_results,\n","    args.n_best_size,\n","    args.max_answer_length,\n","    args.do_lower_case,\n","    output_prediction_file,\n","    output_nbest_file=None,\n","    output_null_log_odds_file=None,\n","    verbose_logging=False,\n","    version_2_with_negative=False,\n","    null_score_diff_threshold=0.0,\n","    tokenizer=tokenizer\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhyqZJulwXOv"},"source":["results = squad_evaluate(eval_examples, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KJq5ezZweiX"},"source":["results"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DfSNpuajkdUw"},"source":["predictions"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"70zUvpYqJD_7"},"source":[""],"execution_count":null,"outputs":[]}]}